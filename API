#################################################################################################
#                                  WINDFLOW ACCEPTED SIGNATURES                                 #
#################################################################################################

This file lists all the possible signatures that can be used to create WindFlow operators. In case
you provide a wrong signature during the creation of an operator (through its builder), you receive
a specific error message during the compilation phase (through static asserts).

For basic and window-based operators, the functional logic, as well as the key extractor and the
closing logic can be provided as functions, lambdas or functor objects providing operator() with
the right signature.

For Map_GPU and Filter_GPU operators, the functional logic must be provided as a __device__ lambda
or through a functor object exposing a __device__ operator() method with the right signature. The
key extractor logic must be provided using a __host__ __device__ lambda or functor object.

SOURCE
------
bool(Source_Shipper<tuple_t> &);
bool(Source_Shipper<tuple_t> &, RuntimeContext &);

FILTER
------
bool(tuple_t &);
bool(tuple_t &, RuntimeContext &);

FILTER_GPU
----------
__device__ bool(tuple_t &);
__device__ bool(tuple_t &, state_t &);

MAP
---
void(tuple_t &);
void(tuple_t &, RuntimeContext &);
result_t(const tuple_t &);
result_t(const tuple_t &, RuntimeContext &);

MAP_GPU
-------
__device__ void(tuple_t &);
__device__ void(tuple_t &, state_t &);

FLATMAP
-------
void(const tuple_t &, Shipper<result_t> &);
void(const tuple_t &, Shipper<result_t> &, RuntimeContext &);

REDUCE
------
void(const tuple_t &, result_t &);
void(const tuple_t &, result_t &, RuntimeContext &);

KEYED_WINDOWS, PARALLEL_WINDOWS
-------------------------------
void(const Iterable<tuple_t> &, result_t &);
void(const Iterable<tuple_t> &, result_t &, RuntimeContext &);
void(const tuple_t &, result_t &);
void(const tuple_t &, result_t &, RuntimeContext &);

PANED_WINDOWS
-------------
The corresponding builder needs two parameters (for the PLQ and WLQ logics) with the following accepted signatures:

 * PLQ
    void(const Iterable<tuple_t> &, tuple_t &);
    void(const Iterable<tuple_t> &, tuple_t &, RuntimeContext &);
    void(const tuple_t &, tuple_t &);
    void(const tuple_t &, tuple_t &, RuntimeContext &);

 * WLQ
    void(const Iterable<tuple_t> &, result_t &);
    void(const Iterable<tuple_t> &, result_t &, RuntimeContext &);
    void(const tuple_t &, result_t &);
    void(const tuple_t &, result_t &, RuntimeContext &);

MAPREDUCE_WINDOWS
-----------------
The corresponding builder needs two parameters (for the MAP and REDUCE logics) with the following accepted signatures:

 * MAP
    void(const Iterable<tuple_t> &, tuple_t &);
    void(const Iterable<tuple_t> &, tuple_t &, RuntimeContext &);
    void(const tuple_t &, tuple_t &);
    void(const tuple_t &, tuple_t &, RuntimeContext &);

 * REDUCE
    void(const Iterable<tuple_t> &, result_t &);
    void(const Iterable<tuple_t> &, result_t &, RuntimeContext &);
    void(const tuple_t &, result_t &);
    void(const tuple_t &, result_t &, RuntimeContext &);

FFAT_ACCUMULATOR
----------------
The corresponding builder needs two parameters (for the lift and combine logics) with the following accepted signatures:

 * Lift
    void(const tuple_t &, result_t &);
    void(const tuple_t &, result_t &, RuntimeContext &);

 * Combine
    void(const result_t &, const result_t &, result_t &);
    void(const result_t &, const result_t &, result_t &, RuntimeContext &);

SINK
----
void(std::optional<tuple_t> &);
void(std::optional<tuple_t> &, RuntimeContext &);
void(std::optional<std::reference_wrapper<tuple_t>>)
void(std::optional<std::reference_wrapper<tuple_t>>, RuntimeContext &)

CLOSING LOGIC
-------------
void(RuntimeContext &);

KEY EXTRACTOR
-------------
key_t(const tuple_t &); // for all the CPU operators
__host__ __device__ key_t(const tuple_t &); // only for Map_GPU and Filter_GPU operators

SPLITTING LOGIC
---------------
integral_t(const tuple_t &);
std::vector<integral_t>(const tuple_t &);
integral_t(tuple_t &);
std::vector<integral_t>(tuple_t &);

Where integral_t is any C++ integral type (e.g., short, int, long, and so forth).

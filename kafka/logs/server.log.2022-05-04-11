[2022-05-04 11:25:20,361] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:25:20,364] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:25:20,371] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:25:20,371] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:25:20,371] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:25:20,371] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:25:20,375] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:25:20,376] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:25:20,376] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:25:20,376] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-04 11:25:20,384] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-04 11:25:20,408] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:25:20,408] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:25:20,409] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:25:20,409] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:25:20,410] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:25:20,410] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:25:20,411] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-04 11:25:20,434] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@589b3632 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-04 11:25:20,441] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:25:20,460] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,460] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,461] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,461] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,461] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,461] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,461] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,461] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,461] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,462] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,465] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,465] INFO Server environment:host.name=fedora (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,465] INFO Server environment:java.version=16.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,465] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,465] INFO Server environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,465] INFO Server environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,466] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,466] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,466] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,466] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,466] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,466] INFO Server environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,466] INFO Server environment:user.name=della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,466] INFO Server environment:user.home=/home/della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,467] INFO Server environment:user.dir=/home/della/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,467] INFO Server environment:os.memory.free=495MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,467] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,467] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,467] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,467] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,467] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,467] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,468] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,468] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,468] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,470] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-04 11:25:20,472] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,473] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,475] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:25:20,475] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:25:20,477] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:25:20,478] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:25:20,478] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:25:20,478] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:25:20,478] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:25:20,479] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:25:20,483] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,483] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,483] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,500] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:25:20,501] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:25:20,503] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:25:20,511] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:25:20,533] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:25:20,533] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:25:20,534] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:25:20,534] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:25:20,541] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-04 11:25:20,543] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.1b5 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-05-04 11:25:20,569] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x1b5, and digest value as 307503178820 (org.apache.zookeeper.server.DataTree)
[2022-05-04 11:25:20,627] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-04 11:25:20,636] INFO 118 txns loaded in 46 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:25:20,637] INFO Snapshot loaded in 103 ms, highest zxid is 0x22b, digest is 297987800299 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:25:20,637] INFO Snapshotting: 0x22b to /tmp/zookeeper/version-2/snapshot.22b (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:25:20,642] INFO Snapshot taken in 5 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:25:20,660] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-04 11:25:20,661] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-04 11:25:20,699] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-04 11:25:48,735] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:25:49,044] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:25:49,201] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:25:49,208] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:25:49,208] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:25:49,232] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:25:49,239] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,239] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,239] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,239] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,239] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,239] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,240] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,240] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,240] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,240] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,240] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,240] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,240] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,241] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,241] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,241] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,241] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,241] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,245] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:49,257] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:25:49,265] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:25:49,268] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:25:49,275] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:25:49,275] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:25:49,279] INFO Socket connection established, initiating session, client: /127.0.0.1:42598, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:25:49,292] INFO Creating new log file: log.22c (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-04 11:25:49,299] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10000e477640000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:25:49,305] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:25:49,417] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:25:49,604] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:25:49,613] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:25:49,617] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:25:49,675] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:25:49,692] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:25:49,747] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:25:49,748] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:25:49,750] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:25:49,751] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:25:49,775] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:25:49,817] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 11:25:49,827] INFO Attempting recovery for all logs in /tmp/kafka-logs-1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:25:49,836] INFO Loaded 0 logs in 19ms. (kafka.log.LogManager)
[2022-05-04 11:25:49,837] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:25:49,842] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:25:50,250] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:25:50,617] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:25:50,623] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-04 11:25:50,681] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:25:50,697] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:25:50,731] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:50,737] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:50,735] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:50,733] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:50,763] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:25:50,834] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:25:50,869] INFO Stat of the created znode at /brokers/ids/1 is: 571,571,1651656350859,1651656350859,1,0,0,72058575293513728,196,0,571
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:25:50,871] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://fedora:9092, czxid (broker epoch): 571 (kafka.zk.KafkaZkClient)
[2022-05-04 11:25:50,953] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:50,961] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:50,963] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:50,993] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:51,035] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:51,070] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:25:51,081] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:25:51,081] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:25:51,132] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:51,186] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:25:51,245] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:25:51,251] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:25:51,252] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:25:51,261] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:25:51,261] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:25:51,261] INFO Kafka startTimeMs: 1651656351253 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:25:51,263] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-04 11:25:51,404] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:25:51,480] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:25:51,640] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, provatop-0, __consumer_offsets-46, output-0, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-48, __consumer_offsets-12, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-8, __consumer_offsets-4, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:25:51,727] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,747] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-1/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,751] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-04 11:25:51,752] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,774] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,777] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-1/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,778] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-04 11:25:51,778] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,787] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,790] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-1/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,790] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-04 11:25:51,790] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,800] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,805] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-1/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,806] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-04 11:25:51,806] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,820] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,824] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-1/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,825] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-04 11:25:51,826] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,847] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,849] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-1/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,849] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-04 11:25:51,849] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,859] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,862] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-1/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,862] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-04 11:25:51,862] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,877] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,879] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-1/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,879] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-04 11:25:51,879] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,887] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,889] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-1/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,889] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-04 11:25:51,889] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,901] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,904] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-1/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,905] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-04 11:25:51,905] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,917] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,921] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-1/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,921] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-04 11:25:51,922] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,932] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,934] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-1/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,934] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-04 11:25:51,936] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,947] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,950] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-1/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,950] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,950] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,967] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,968] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-1/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,968] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-04 11:25:51,968] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,984] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,987] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-1/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,987] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-04 11:25:51,987] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:51,996] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:51,998] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-1/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:51,998] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-04 11:25:51,998] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,006] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:52,009] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-1/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:52,010] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-04 11:25:52,010] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,017] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:52,021] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-1/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:52,021] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-04 11:25:52,021] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,031] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:52,037] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-1/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:52,038] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-04 11:25:52,039] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,051] INFO [LogLoader partition=output-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:52,054] INFO Created log for partition output-0 in /tmp/kafka-logs-1/output-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:25:52,054] INFO [Partition output-0 broker=1] No checkpointed highwatermark is found for partition output-0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,054] INFO [Partition output-0 broker=1] Log loaded for partition output-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,063] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:52,065] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-1/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:52,065] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-04 11:25:52,065] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,073] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:52,079] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-1/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:52,079] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-04 11:25:52,079] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,089] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:52,095] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-1/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:52,095] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-04 11:25:52,095] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,104] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:52,107] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-1/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:52,107] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-04 11:25:52,107] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,115] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:52,118] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-1/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:52,118] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-04 11:25:52,118] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,127] INFO [LogLoader partition=provatop-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:52,129] INFO Created log for partition provatop-0 in /tmp/kafka-logs-1/provatop-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:25:52,129] INFO [Partition provatop-0 broker=1] No checkpointed highwatermark is found for partition provatop-0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,129] INFO [Partition provatop-0 broker=1] Log loaded for partition provatop-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,135] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:52,138] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-1/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:52,138] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-04 11:25:52,138] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:52,148] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,150] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,153] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,153] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,153] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,153] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,154] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,154] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,154] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,154] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,154] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,154] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,154] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,155] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,155] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,155] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,155] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,155] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,155] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,155] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,155] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,155] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,155] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,155] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,155] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,155] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,159] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,159] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,159] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,160] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,160] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,160] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,161] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,161] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,161] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,161] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,161] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,161] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,162] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,162] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,162] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,162] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,162] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,162] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,162] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,163] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,163] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,163] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,163] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:52,163] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,170] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 12 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,171] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 18 milliseconds for epoch 2, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,172] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 18 milliseconds for epoch 2, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,172] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 18 milliseconds for epoch 2, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,173] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 19 milliseconds for epoch 2, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,177] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 22 milliseconds for epoch 2, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,177] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 22 milliseconds for epoch 2, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,182] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 26 milliseconds for epoch 2, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,183] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 28 milliseconds for epoch 2, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,183] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 28 milliseconds for epoch 2, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,184] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 29 milliseconds for epoch 2, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,184] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 29 milliseconds for epoch 2, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,186] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 27 milliseconds for epoch 2, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,187] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 28 milliseconds for epoch 2, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 27 milliseconds for epoch 2, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 27 milliseconds for epoch 2, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 27 milliseconds for epoch 2, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,189] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 28 milliseconds for epoch 2, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,190] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 28 milliseconds for epoch 2, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,191] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 29 milliseconds for epoch 2, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,193] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 31 milliseconds for epoch 2, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,194] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 32 milliseconds for epoch 2, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,194] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 31 milliseconds for epoch 2, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,195] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 32 milliseconds for epoch 2, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:52,200] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 36 milliseconds for epoch 2, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:53,031] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:25:53,350] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:25:53,461] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:25:53,467] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:25:53,468] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:25:53,488] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:25:53,496] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,497] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,497] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,497] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,497] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,497] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,497] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,498] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,498] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,498] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,498] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,498] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,498] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,498] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,498] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,498] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,498] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,498] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,502] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:25:53,514] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:25:53,522] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:25:53,528] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:25:53,531] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:25:53,531] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:25:53,534] INFO Socket connection established, initiating session, client: /127.0.0.1:42600, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:25:53,541] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10000e477640001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:25:53,546] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:25:53,623] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:25:53,779] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:25:53,787] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:25:53,793] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:25:53,847] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:25:53,862] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:25:53,910] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:25:53,911] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:25:53,912] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:25:53,914] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:25:53,932] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:25:53,970] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 11:25:53,976] INFO Attempting recovery for all logs in /tmp/kafka-logs-2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:25:53,984] INFO Loaded 0 logs in 15ms. (kafka.log.LogManager)
[2022-05-04 11:25:53,985] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:25:53,992] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:25:54,347] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:25:54,667] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:25:54,675] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-04 11:25:54,725] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:25:54,741] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:25:54,777] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:54,779] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:54,781] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:54,783] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:54,806] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:25:54,879] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:25:54,900] INFO Stat of the created znode at /brokers/ids/2 is: 615,615,1651656354892,1651656354892,1,0,0,72058575293513729,196,0,615
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:25:54,902] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://fedora:9093, czxid (broker epoch): 615 (kafka.zk.KafkaZkClient)
[2022-05-04 11:25:55,023] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:55,032] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:55,034] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:55,054] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,081] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,106] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:25:55,111] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:25:55,111] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:25:55,144] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:25:55,168] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:25:55,197] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:25:55,212] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:25:55,212] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:25:55,218] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:25:55,218] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:25:55,218] INFO Kafka startTimeMs: 1651656355212 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:25:55,221] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-04 11:25:55,348] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:25:55,366] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:25:55,464] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,494] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-2/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,498] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-04 11:25:55,499] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,510] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,515] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-2/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,515] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-04 11:25:55,515] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,528] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,530] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-2/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,530] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-04 11:25:55,531] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,545] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,549] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-2/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,549] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-04 11:25:55,549] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,561] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,563] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-2/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,563] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-04 11:25:55,564] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,572] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,575] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-2/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,575] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-04 11:25:55,575] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,582] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,583] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-2/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,584] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-04 11:25:55,584] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,591] INFO [LogLoader partition=input-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,594] INFO Created log for partition input-0 in /tmp/kafka-logs-2/input-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:25:55,595] INFO [Partition input-0 broker=2] No checkpointed highwatermark is found for partition input-0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,595] INFO [Partition input-0 broker=2] Log loaded for partition input-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,601] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,604] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-2/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,604] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-04 11:25:55,604] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,613] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,615] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-2/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,615] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-04 11:25:55,616] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,627] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,628] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-2/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,629] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-04 11:25:55,629] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,637] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,639] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-2/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,640] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-04 11:25:55,640] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,648] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,649] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-2/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,650] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-04 11:25:55,650] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,656] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,659] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-2/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,659] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-04 11:25:55,660] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,665] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,666] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-2/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,667] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-04 11:25:55,667] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,676] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,677] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-2/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,678] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-04 11:25:55,678] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,684] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,686] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-2/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,687] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-04 11:25:55,687] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,695] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,697] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-2/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,697] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-04 11:25:55,697] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,706] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,710] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-2/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,711] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-04 11:25:55,711] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,718] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,721] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-2/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,722] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-04 11:25:55,722] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,731] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,732] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-2/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,733] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-04 11:25:55,733] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,745] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,747] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-2/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,747] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-04 11:25:55,747] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,758] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,760] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-2/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,761] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-04 11:25:55,761] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,767] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,769] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-2/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,769] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-04 11:25:55,770] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,777] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,779] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-2/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,779] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-04 11:25:55,779] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,784] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:25:55,786] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-2/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:25:55,786] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-04 11:25:55,786] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:25:55,826] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, input-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:25:55,871] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 3 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,872] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,875] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,875] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,875] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,876] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,876] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,876] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,876] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,876] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,876] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 33 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,876] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,876] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,876] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,876] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,877] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,877] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,877] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,877] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 45 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,877] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,877] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,877] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,877] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,877] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,877] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,877] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,877] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,878] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,878] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 39 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,878] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,878] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 9 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,878] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,878] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 27 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,878] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,878] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,878] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,878] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,878] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,878] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 21 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,878] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,879] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,879] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,879] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,879] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,879] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,879] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,879] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,879] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,879] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:25:55,879] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,893] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 11 milliseconds for epoch 9, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,893] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 18 milliseconds for epoch 9, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,894] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 18 milliseconds for epoch 9, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,894] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 18 milliseconds for epoch 9, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,895] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 19 milliseconds for epoch 9, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,895] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 19 milliseconds for epoch 9, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,895] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 19 milliseconds for epoch 9, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,896] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 19 milliseconds for epoch 9, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,896] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 19 milliseconds for epoch 9, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,896] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 19 milliseconds for epoch 9, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,897] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 20 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,897] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 20 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,898] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 20 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,898] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 20 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,898] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 20 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,898] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 20 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,899] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 21 milliseconds for epoch 9, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,899] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 21 milliseconds for epoch 9, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,900] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 22 milliseconds for epoch 9, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,900] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 22 milliseconds for epoch 9, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,900] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 21 milliseconds for epoch 9, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,901] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 22 milliseconds for epoch 9, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,901] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 22 milliseconds for epoch 9, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,901] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 22 milliseconds for epoch 9, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:25:55,902] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 23 milliseconds for epoch 9, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:26:44,559] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group console-consumer-30796 in Empty state. Created a new member id console-consumer-831ec26d-6402-4a02-ac98-1e0651563ab5 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:26:44,577] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-30796 in state PreparingRebalance with old generation 0 (__consumer_offsets-16) (reason: Adding new member console-consumer-831ec26d-6402-4a02-ac98-1e0651563ab5 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:26:44,589] INFO [GroupCoordinator 1]: Stabilized group console-consumer-30796 generation 1 (__consumer_offsets-16) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:26:44,614] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-831ec26d-6402-4a02-ac98-1e0651563ab5 for group console-consumer-30796 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:26:48,953] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-74a90356-a28b-4dbf-85e0-8e957c7bb649 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:26:49,059] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member rdkafka-74a90356-a28b-4dbf-85e0-8e957c7bb649 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:26:49,106] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 1 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:26:49,172] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-74a90356-a28b-4dbf-85e0-8e957c7bb649 for group gruppo for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:27:14,600] INFO [LocalLog partition=input-0, dir=/tmp/kafka-logs-2] Rolled new log segment at offset 14729519 in 8 ms. (kafka.log.LocalLog)
[2022-05-04 11:27:14,607] INFO [ProducerStateManager partition=input-0] Wrote producer snapshot at offset 14729519 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:27:46,727] INFO [LocalLog partition=input-0, dir=/tmp/kafka-logs-2] Rolled new log segment at offset 29452525 in 3 ms. (kafka.log.LocalLog)
[2022-05-04 11:27:46,734] INFO [ProducerStateManager partition=input-0] Wrote producer snapshot at offset 29452525 with 0 producer ids in 0 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:27:48,971] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: Removing member rdkafka-74a90356-a28b-4dbf-85e0-8e957c7bb649 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:27:48,973] INFO [GroupCoordinator 2]: Group gruppo with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:27:48,977] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-74a90356-a28b-4dbf-85e0-8e957c7bb649, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.1.114, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:27:59,587] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-bc286830-21d0-41c0-9065-c9580b3d76b4 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:27:59,593] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 2 (__consumer_offsets-37) (reason: Adding new member rdkafka-bc286830-21d0-41c0-9065-c9580b3d76b4 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:27:59,595] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 3 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:27:59,603] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-bc286830-21d0-41c0-9065-c9580b3d76b4 for group gruppo for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:28:59,472] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 3 (__consumer_offsets-37) (reason: Removing member rdkafka-bc286830-21d0-41c0-9065-c9580b3d76b4 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:28:59,472] INFO [GroupCoordinator 2]: Group gruppo with generation 4 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:28:59,473] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-bc286830-21d0-41c0-9065-c9580b3d76b4, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.1.114, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:29:13,672] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:29:13,682] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-04 11:29:13,682] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 11:29:13,715] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 17ms (kafka.server.KafkaServer)
[2022-05-04 11:29:13,729] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:29:13,729] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:29:13,731] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:29:13,732] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:29:13,748] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:29:13,750] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:29:13,753] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:29:13,759] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:13,938] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:13,938] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:13,939] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 11:29:13,941] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:13,980] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:13,980] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:13,983] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:29:13,984] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 11:29:13,984] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:29:13,984] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:29:13,984] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:29:13,985] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:29:13,987] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:29:13,987] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,079] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,079] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,080] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,085] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,086] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,088] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:29:14,089] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 11:29:14,089] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:29:14,090] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:29:14,090] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:29:14,091] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:29:14,093] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:29:14,093] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:29:14,093] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:29:14,093] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,255] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,255] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,255] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,380] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,380] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,381] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,566] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:29:14,569] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-04 11:29:14,571] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 11:29:14,580] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,580] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,581] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,594] INFO [KafkaServer id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-04 11:29:14,597] WARN [KafkaServer id=2] Connection to node 1 (fedora/192.168.1.114:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-04 11:29:14,597] WARN [KafkaServer id=2] Error during controlled shutdown, possibly because leader movement took longer than the configured controller.socket.timeout.ms and/or request.timeout.ms: Connection to fedora:9092 (id: 1 rack: null) failed. (kafka.server.KafkaServer)
[2022-05-04 11:29:14,777] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,777] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:14,780] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 11:29:14,780] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:29:14,781] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:29:14,781] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:29:14,783] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:29:14,784] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:29:14,784] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:29:14,784] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:29:14,785] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:29:14,787] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 11:29:14,827] INFO [ProducerStateManager partition=output-0] Wrote producer snapshot at offset 72831 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:29:14,830] INFO [ProducerStateManager partition=__consumer_offsets-16] Wrote producer snapshot at offset 1 with 0 producer ids in 0 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:29:14,839] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 11:29:14,852] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:29:14,852] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:29:14,852] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:29:14,853] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:29:14,965] INFO EventThread shut down for session: 0x10000e477640000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:29:14,966] INFO Session: 0x10000e477640000 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:29:14,970] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:29:14,971] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:15,832] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:15,832] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:15,833] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:15,887] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:15,887] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:15,887] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:16,835] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:16,835] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:16,835] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:17,818] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:17,818] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:17,820] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 11:29:17,880] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 11:29:17,881] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:29:17,881] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:29:17,882] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:29:17,885] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 11:29:17,887] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:29:17,888] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-04 11:29:19,598] INFO [KafkaServer id=2] Retrying controlled shutdown (2 retries remaining) (kafka.server.KafkaServer)
[2022-05-04 11:29:19,598] INFO [KafkaServer id=2] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 11:29:19,612] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2022-05-04 11:29:19,622] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:29:19,624] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:29:19,625] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:29:19,627] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:29:19,636] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:29:19,637] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:29:19,640] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:29:19,644] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:19,793] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:19,793] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:19,795] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 11:29:19,798] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:19,816] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:19,816] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:19,820] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:29:19,821] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 11:29:19,821] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:29:19,821] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:29:19,821] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:29:19,822] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:29:19,823] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:29:19,824] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:19,877] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:19,877] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:19,879] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,046] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,046] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,047] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:29:20,051] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 11:29:20,052] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:29:20,053] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:29:20,053] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:29:20,054] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:29:20,056] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:29:20,057] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:29:20,057] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:29:20,058] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,226] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,226] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,227] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,229] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,229] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,230] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,250] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,250] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,251] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,423] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,423] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:29:20,427] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 11:29:20,428] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:29:20,428] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:29:20,428] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:29:20,431] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:29:20,431] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:29:20,431] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:29:20,431] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:29:20,432] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:29:20,432] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 11:29:20,448] INFO [ProducerStateManager partition=__consumer_offsets-37] Wrote producer snapshot at offset 29 with 0 producer ids in 0 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:29:20,451] INFO [ProducerStateManager partition=input-0] Wrote producer snapshot at offset 34139291 with 0 producer ids in 0 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:29:20,457] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 11:29:20,466] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:29:20,466] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:29:20,466] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:29:20,467] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:29:20,573] INFO Session: 0x10000e477640001 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:29:20,573] INFO EventThread shut down for session: 0x10000e477640001 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:29:20,575] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:29:20,576] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:20,994] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:20,994] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:20,995] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:21,962] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:21,962] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:21,963] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:21,973] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:21,973] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:21,974] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:22,962] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:22,962] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:29:22,966] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 11:29:23,038] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 11:29:23,038] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:29:23,039] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:29:23,039] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:29:23,043] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 11:29:23,044] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:29:23,045] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-04 11:29:39,508] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:29:39,511] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:29:39,517] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:29:39,518] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:29:39,518] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:29:39,518] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:29:39,523] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:29:39,524] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:29:39,524] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:29:39,524] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-04 11:29:39,531] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-04 11:29:39,555] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:29:39,555] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:29:39,556] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:29:39,556] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:29:39,556] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:29:39,556] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:29:39,557] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-04 11:29:39,583] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@ca263c2 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-04 11:29:39,589] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:29:39,611] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,611] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,612] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,612] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,612] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,612] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,612] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,612] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,612] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,612] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,615] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,615] INFO Server environment:host.name=fedora (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,615] INFO Server environment:java.version=16.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,615] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,615] INFO Server environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,615] INFO Server environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,616] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,616] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,616] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,616] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,616] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,616] INFO Server environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,616] INFO Server environment:user.name=della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,616] INFO Server environment:user.home=/home/della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,616] INFO Server environment:user.dir=/home/della/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,617] INFO Server environment:os.memory.free=495MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,617] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,617] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,617] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,617] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,617] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,617] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,617] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,618] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,618] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,620] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-04 11:29:39,622] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,623] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,625] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:29:39,625] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:29:39,628] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:29:39,628] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:29:39,629] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:29:39,629] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:29:39,629] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:29:39,629] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:29:39,633] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,633] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,634] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,651] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:29:39,653] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:29:39,657] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:29:39,664] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:29:39,689] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:29:39,690] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:29:39,690] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:29:39,690] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:29:39,700] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-04 11:29:39,701] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.22b (org.apache.zookeeper.server.persistence.FileSnap)
[2022-05-04 11:29:39,718] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x22b, and digest value as 297987800299 (org.apache.zookeeper.server.DataTree)
[2022-05-04 11:29:39,761] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-04 11:29:39,767] INFO 117 txns loaded in 35 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:29:39,767] INFO Snapshot loaded in 76 ms, highest zxid is 0x2a0, digest is 296726674909 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:29:39,767] INFO Snapshotting: 0x2a0 to /tmp/zookeeper/version-2/snapshot.2a0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:29:39,775] INFO Snapshot taken in 9 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:29:39,791] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-04 11:29:39,791] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-04 11:29:39,828] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-04 11:30:07,643] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:30:08,280] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:30:08,531] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:30:08,544] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:30:08,548] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:30:08,608] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:30:08,619] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,620] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,620] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,620] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,620] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,620] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,621] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,621] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,621] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,621] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,621] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,622] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,622] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,622] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,622] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,622] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,622] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,622] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,632] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:08,651] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:30:08,668] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:30:08,684] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:30:08,689] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:30:08,690] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:30:08,698] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:40468, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:30:08,711] INFO Creating new log file: log.2a1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-04 11:30:08,722] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10000e86ba00000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:30:08,730] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:30:08,772] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:30:08,935] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:30:09,213] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:30:09,256] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:30:09,277] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:30:09,284] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:30:09,412] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:30:09,457] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:30:09,486] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:30:09,505] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:30:09,513] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:30:09,556] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:30:09,558] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:30:09,560] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:30:09,562] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:30:09,564] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,564] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,564] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,564] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,564] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,565] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,565] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,565] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,565] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,565] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,565] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,565] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,565] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,566] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,566] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,566] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,566] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,566] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,566] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:30:09,571] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7d94beb9 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:30:09,592] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:30:09,598] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:30:09,608] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:30:09,627] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:30:09,633] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:30:09,633] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:30:09,645] INFO Socket connection established, initiating session, client: /127.0.0.1:42602, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:30:09,657] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10000e86ba00001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:30:09,668] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:30:09,678] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 11:30:09,688] INFO Attempting recovery for all logs in /tmp/kafka-logs-1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:30:09,714] INFO Loaded 0 logs in 36ms. (kafka.log.LogManager)
[2022-05-04 11:30:09,717] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:30:09,726] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:30:09,818] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:30:10,071] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:30:10,116] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:30:10,136] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:30:10,238] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:30:10,253] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:30:10,287] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:30:10,333] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:30:10,336] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:30:10,338] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:30:10,340] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:30:10,377] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:30:10,458] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 11:30:10,476] INFO Attempting recovery for all logs in /tmp/kafka-logs-2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:30:10,497] INFO Loaded 0 logs in 37ms. (kafka.log.LogManager)
[2022-05-04 11:30:10,503] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:30:10,513] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:30:11,000] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:30:11,007] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-04 11:30:11,116] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:30:11,180] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:30:11,210] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:11,217] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:11,221] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:11,222] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:11,256] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:30:11,311] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:30:11,363] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:30:11,423] INFO Stat of the created znode at /brokers/ids/1 is: 703,703,1651656611410,1651656611410,1,0,0,72058592275988480,196,0,703
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:30:11,425] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://fedora:9092, czxid (broker epoch): 703 (kafka.zk.KafkaZkClient)
[2022-05-04 11:30:11,598] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:11,606] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:11,620] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:11,702] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:11,757] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:11,858] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:30:11,980] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:30:11,986] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:30:12,062] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:12,190] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:30:12,392] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:30:12,431] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:30:12,483] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-04 11:30:12,505] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:30:12,506] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:30:12,518] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:30:12,519] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:30:12,519] INFO Kafka startTimeMs: 1651656612506 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:30:12,521] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-04 11:30:12,584] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:30:12,597] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:30:12,646] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:30:12,676] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:30:12,719] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:12,722] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:12,731] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:12,727] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:12,817] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:30:12,984] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:30:13,019] INFO Stat of the created znode at /brokers/ids/2 is: 731,731,1651656613006,1651656613006,1,0,0,72058592275988481,196,0,731
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:30:13,021] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://fedora:9093, czxid (broker epoch): 731 (kafka.zk.KafkaZkClient)
[2022-05-04 11:30:13,189] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:13,212] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:13,219] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:13,280] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:13,334] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:13,408] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:30:13,418] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:30:13,422] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:30:13,524] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:30:13,524] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,584] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-1/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,587] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-04 11:30:13,593] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,603] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,617] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:30:13,612] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-1/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,619] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-04 11:30:13,619] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,637] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,640] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-1/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,640] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-04 11:30:13,640] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,652] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,661] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-1/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,661] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-04 11:30:13,662] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,681] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,687] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-1/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,688] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-04 11:30:13,688] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,689] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:30:13,700] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,707] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-1/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,708] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-04 11:30:13,709] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,713] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:30:13,714] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:30:13,727] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:30:13,727] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:30:13,737] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,746] INFO Kafka startTimeMs: 1651656613715 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:30:13,749] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-04 11:30:13,749] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-1/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,750] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-04 11:30:13,755] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,772] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,780] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-1/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,781] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-04 11:30:13,781] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,805] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,811] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-1/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,811] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-04 11:30:13,814] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,832] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,839] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-1/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,839] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-04 11:30:13,839] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,863] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,873] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-1/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,874] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-04 11:30:13,874] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,895] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,910] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-1/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,911] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-04 11:30:13,912] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,940] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,960] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-1/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,960] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,960] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:13,968] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:13,968] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:30:13,980] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:30:13,980] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-1/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:13,981] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-04 11:30:13,981] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,003] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,016] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-1/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,016] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-04 11:30:14,017] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,036] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,038] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-1/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,038] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-04 11:30:14,038] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,055] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,061] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-1/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,061] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-04 11:30:14,063] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,076] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,078] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-1/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,079] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-04 11:30:14,079] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,096] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,100] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-1/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,100] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-04 11:30:14,100] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,117] INFO [LogLoader partition=output-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,120] INFO Created log for partition output-0 in /tmp/kafka-logs-1/output-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:30:14,120] INFO [Partition output-0 broker=1] No checkpointed highwatermark is found for partition output-0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,120] INFO [Partition output-0 broker=1] Log loaded for partition output-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,147] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,148] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-1/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,148] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-04 11:30:14,149] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,176] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,180] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-1/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,182] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-04 11:30:14,182] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,199] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,201] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-1/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,201] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-04 11:30:14,201] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,225] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,230] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-1/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,231] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-04 11:30:14,231] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,243] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,246] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-1/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,247] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-04 11:30:14,247] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,260] INFO [LogLoader partition=provatop-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,264] INFO Created log for partition provatop-0 in /tmp/kafka-logs-1/provatop-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:30:14,265] INFO [Partition provatop-0 broker=1] No checkpointed highwatermark is found for partition provatop-0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,265] INFO [Partition provatop-0 broker=1] Log loaded for partition provatop-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,280] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,282] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-1/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,289] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-04 11:30:14,289] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,388] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, provatop-0, __consumer_offsets-46, output-0, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-48, __consumer_offsets-12, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-8, __consumer_offsets-4, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:30:14,392] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,421] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-2/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,428] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-04 11:30:14,430] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,446] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,452] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-2/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,453] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-04 11:30:14,453] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,471] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,476] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-2/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,477] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-04 11:30:14,477] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,484] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,487] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-2/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,487] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-04 11:30:14,487] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,503] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,505] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-2/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,505] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-04 11:30:14,517] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,529] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,531] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-2/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,531] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-04 11:30:14,531] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,547] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,548] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-2/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,548] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-04 11:30:14,549] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,550] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,552] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,563] INFO [LogLoader partition=input-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,566] INFO Created log for partition input-0 in /tmp/kafka-logs-2/input-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:30:14,566] INFO [Partition input-0 broker=2] No checkpointed highwatermark is found for partition input-0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,566] INFO [Partition input-0 broker=2] Log loaded for partition input-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,572] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,572] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,572] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,573] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,576] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,576] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,577] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,577] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,577] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,577] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,579] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,579] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,580] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,580] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,580] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,580] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,580] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,580] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,580] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,580] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,580] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,580] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,580] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,580] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,580] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,580] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,583] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,583] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,583] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,583] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,583] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,583] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,583] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,583] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,583] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,583] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,584] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:14,584] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,582] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 22 milliseconds for epoch 4, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,587] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 15 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,587] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 13 milliseconds for epoch 4, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,590] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 14 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,591] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 14 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,592] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 13 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,593] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 14 milliseconds for epoch 4, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,593] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 13 milliseconds for epoch 4, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,594] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,594] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 14 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,594] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 14 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,595] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 15 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,596] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 16 milliseconds for epoch 4, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,596] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 16 milliseconds for epoch 4, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,597] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-2/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,597] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 14 milliseconds for epoch 4, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,597] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-04 11:30:14,597] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,597] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 14 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,598] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 14 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,598] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 15 milliseconds for epoch 4, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,614] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,616] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-2/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,616] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-04 11:30:14,616] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,628] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 45 milliseconds for epoch 4, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,629] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 46 milliseconds for epoch 4, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,629] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 45 milliseconds for epoch 4, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,630] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 46 milliseconds for epoch 4, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,630] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 46 milliseconds for epoch 4, of which 46 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,634] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,636] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 52 milliseconds for epoch 4, of which 46 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,637] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 53 milliseconds for epoch 4, of which 53 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,637] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 53 milliseconds for epoch 4, of which 53 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:14,640] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-2/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,640] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-04 11:30:14,641] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,660] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,663] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-2/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,664] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-04 11:30:14,665] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,672] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,677] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-2/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,677] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-04 11:30:14,678] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,685] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,688] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-2/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,688] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-04 11:30:14,688] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,695] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,698] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-2/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,698] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-04 11:30:14,699] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,707] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,726] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-2/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,726] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-04 11:30:14,727] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,738] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,743] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-2/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,743] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-04 11:30:14,744] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,756] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,761] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-2/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,762] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-04 11:30:14,762] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,774] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,779] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-2/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,779] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-04 11:30:14,779] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,795] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,800] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-2/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,800] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-04 11:30:14,800] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,824] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,828] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-2/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,828] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-04 11:30:14,828] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,846] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,850] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-2/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,852] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-04 11:30:14,852] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,868] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,880] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-2/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,880] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-04 11:30:14,881] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,911] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,916] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-2/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,916] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-04 11:30:14,916] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,934] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,938] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-2/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,938] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-04 11:30:14,941] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:14,960] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:30:14,963] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-2/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:30:14,963] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-04 11:30:14,963] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:30:15,047] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, input-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:30:15,178] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 3 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,180] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,184] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,184] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,184] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,184] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,188] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,194] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,194] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,194] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,195] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 33 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,195] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,195] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,195] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,196] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,196] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,196] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,196] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,196] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 45 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,196] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,196] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,196] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,197] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,197] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,197] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,197] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,197] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,197] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,197] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 39 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,197] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,197] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 9 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,197] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,197] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 27 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,197] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,198] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,198] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,199] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,199] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,199] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 21 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,209] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,209] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,209] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,209] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,210] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,210] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,210] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:15,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,229] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 36 milliseconds for epoch 11, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,232] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 47 milliseconds for epoch 11, of which 47 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,232] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 48 milliseconds for epoch 11, of which 48 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,233] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 38 milliseconds for epoch 11, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,233] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 38 milliseconds for epoch 11, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,233] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 38 milliseconds for epoch 11, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,234] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 39 milliseconds for epoch 11, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,234] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 38 milliseconds for epoch 11, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,236] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 39 milliseconds for epoch 11, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,237] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 41 milliseconds for epoch 11, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,237] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 41 milliseconds for epoch 11, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,238] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 41 milliseconds for epoch 11, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,238] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 41 milliseconds for epoch 11, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,242] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 45 milliseconds for epoch 11, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,243] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 45 milliseconds for epoch 11, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,244] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 47 milliseconds for epoch 11, of which 46 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,244] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 46 milliseconds for epoch 11, of which 46 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,245] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 47 milliseconds for epoch 11, of which 46 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,246] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 47 milliseconds for epoch 11, of which 47 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,246] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 37 milliseconds for epoch 11, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,247] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 38 milliseconds for epoch 11, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,247] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 37 milliseconds for epoch 11, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,248] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 38 milliseconds for epoch 11, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,249] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 39 milliseconds for epoch 11, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:15,249] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 39 milliseconds for epoch 11, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:30:33,501] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-9dea9655-dcdf-4c63-a934-d17f959fd58a and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:33,537] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member rdkafka-9dea9655-dcdf-4c63-a934-d17f959fd58a with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:33,563] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 1 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:30:33,599] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-9dea9655-dcdf-4c63-a934-d17f959fd58a for group gruppo for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:31:33,412] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: Removing member rdkafka-9dea9655-dcdf-4c63-a934-d17f959fd58a on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:31:33,413] INFO [GroupCoordinator 2]: Group gruppo with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:31:33,416] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-9dea9655-dcdf-4c63-a934-d17f959fd58a, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.1.114, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:32:00,852] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group console-consumer-43781 in Empty state. Created a new member id console-consumer-fbf388d3-df9b-43f2-adc8-739a547e38ad and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:32:00,870] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-43781 in state PreparingRebalance with old generation 0 (__consumer_offsets-24) (reason: Adding new member console-consumer-fbf388d3-df9b-43f2-adc8-739a547e38ad with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:32:00,881] INFO [GroupCoordinator 1]: Stabilized group console-consumer-43781 generation 1 (__consumer_offsets-24) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:32:00,902] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-fbf388d3-df9b-43f2-adc8-739a547e38ad for group console-consumer-43781 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:32:08,224] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-0aea4b2a-3122-4b76-8a6e-5e498a6f286e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:32:08,234] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 2 (__consumer_offsets-37) (reason: Adding new member rdkafka-0aea4b2a-3122-4b76-8a6e-5e498a6f286e with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:32:08,236] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 3 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:32:08,255] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-0aea4b2a-3122-4b76-8a6e-5e498a6f286e for group gruppo for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:33:08,177] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 3 (__consumer_offsets-37) (reason: Removing member rdkafka-0aea4b2a-3122-4b76-8a6e-5e498a6f286e on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:33:08,178] INFO [GroupCoordinator 2]: Group gruppo with generation 4 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:33:08,178] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-0aea4b2a-3122-4b76-8a6e-5e498a6f286e, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.122.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:33:31,398] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-af0716e7-123c-45e0-9b22-81ddb72517ae and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:33:31,399] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 4 (__consumer_offsets-37) (reason: Adding new member rdkafka-af0716e7-123c-45e0-9b22-81ddb72517ae with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:33:31,400] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 5 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:33:31,404] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-af0716e7-123c-45e0-9b22-81ddb72517ae for group gruppo for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:34:31,506] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 5 (__consumer_offsets-37) (reason: Removing member rdkafka-af0716e7-123c-45e0-9b22-81ddb72517ae on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:34:31,506] INFO [GroupCoordinator 2]: Group gruppo with generation 6 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:34:31,506] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-af0716e7-123c-45e0-9b22-81ddb72517ae, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.1.114, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:34:48,058] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-1ac8d47b-bcbb-4e06-837c-c34f07d04fc1 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:34:48,060] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 6 (__consumer_offsets-37) (reason: Adding new member rdkafka-1ac8d47b-bcbb-4e06-837c-c34f07d04fc1 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:34:48,061] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 7 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:34:48,063] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-1ac8d47b-bcbb-4e06-837c-c34f07d04fc1 for group gruppo for generation 7. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:35:48,170] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 7 (__consumer_offsets-37) (reason: Removing member rdkafka-1ac8d47b-bcbb-4e06-837c-c34f07d04fc1 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:35:48,170] INFO [GroupCoordinator 2]: Group gruppo with generation 8 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:35:48,171] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-1ac8d47b-bcbb-4e06-837c-c34f07d04fc1, groupInstanceId=None, clientId=rdkafka, clientHost=/fe80:0:0:0:c7e8:40c5:2b1e:4f28%3, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:36:16,215] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-4ed838ea-f27d-4c58-8cbf-35d9398d09ff and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:36:16,217] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 8 (__consumer_offsets-37) (reason: Adding new member rdkafka-4ed838ea-f27d-4c58-8cbf-35d9398d09ff with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:36:16,217] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 9 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:36:16,221] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-4ed838ea-f27d-4c58-8cbf-35d9398d09ff for group gruppo for generation 9. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:37:16,509] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 9 (__consumer_offsets-37) (reason: Removing member rdkafka-4ed838ea-f27d-4c58-8cbf-35d9398d09ff on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:37:16,509] INFO [GroupCoordinator 2]: Group gruppo with generation 10 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:37:16,510] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-4ed838ea-f27d-4c58-8cbf-35d9398d09ff, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.122.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:37:26,368] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-5a573faa-ee37-4c7b-86be-46e96b885550 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:37:26,369] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 10 (__consumer_offsets-37) (reason: Adding new member rdkafka-5a573faa-ee37-4c7b-86be-46e96b885550 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:37:26,370] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 11 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:37:26,371] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-5a573faa-ee37-4c7b-86be-46e96b885550 for group gruppo for generation 11. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:38:26,379] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 11 (__consumer_offsets-37) (reason: Removing member rdkafka-5a573faa-ee37-4c7b-86be-46e96b885550 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:38:26,380] INFO [GroupCoordinator 2]: Group gruppo with generation 12 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:38:26,380] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-5a573faa-ee37-4c7b-86be-46e96b885550, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.122.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:03,259] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:39:03,260] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-04 11:39:03,262] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 11:39:03,295] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 18ms (kafka.server.KafkaServer)
[2022-05-04 11:39:03,303] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:39:03,304] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:39:03,305] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:39:03,306] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:39:03,326] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:39:03,328] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:39:03,330] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:39:03,335] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:03,530] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:03,530] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:03,532] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 11:39:03,534] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:03,684] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:03,684] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:03,689] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:39:03,690] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 11:39:03,691] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:39:03,691] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:39:03,691] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:39:03,691] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:39:03,692] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:03,692] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:03,877] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:03,877] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:03,878] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,016] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,016] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,017] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:04,018] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 11:39:04,018] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:39:04,019] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:39:04,019] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:39:04,019] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:39:04,021] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:39:04,021] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:39:04,022] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:39:04,022] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,120] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,120] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,121] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,149] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,149] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,150] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,331] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,331] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,332] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,422] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:39:04,531] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,531] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:04,535] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 11:39:04,536] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:04,536] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:04,536] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:04,544] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:39:04,545] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:04,546] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:04,546] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:04,547] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:39:04,549] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 11:39:04,578] INFO [ProducerStateManager partition=__consumer_offsets-37] Wrote producer snapshot at offset 56 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:39:04,581] INFO [ProducerStateManager partition=input-0] Wrote producer snapshot at offset 24598602 with 0 producer ids in 0 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:39:04,586] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 11:39:04,592] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:39:04,592] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:39:04,592] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:39:04,593] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:39:04,697] INFO EventThread shut down for session: 0x10000e86ba00001 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:39:04,697] INFO Session: 0x10000e86ba00001 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:04,698] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:39:04,699] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:05,404] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:05,404] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:05,404] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:05,413] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:05,413] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:05,414] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:05,606] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:39:05,608] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-04 11:39:05,609] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 11:39:05,619] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 4ms (kafka.server.KafkaServer)
[2022-05-04 11:39:05,625] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:39:05,626] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:39:05,626] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:39:05,626] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:39:05,639] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:39:05,642] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:39:05,645] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:39:05,649] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:05,732] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:05,732] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:05,734] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 11:39:05,735] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:05,783] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:05,783] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:05,786] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:39:05,787] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 11:39:05,788] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:39:05,788] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:39:05,788] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:39:05,788] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:39:05,789] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:05,790] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:05,878] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:05,878] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:05,879] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:05,919] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:05,919] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:05,922] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:05,924] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 11:39:05,924] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:39:05,925] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:39:05,925] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:39:05,926] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:39:05,927] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:39:05,928] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:39:05,928] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:39:05,928] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:06,080] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:06,080] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:06,081] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:06,119] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:06,119] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:06,120] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:06,132] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:06,132] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:06,132] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:06,332] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:06,332] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:06,334] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 11:39:06,335] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:06,335] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:06,335] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:06,338] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:39:06,338] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:06,338] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:06,338] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:06,339] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:39:06,340] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 11:39:06,370] INFO [ProducerStateManager partition=output-0] Wrote producer snapshot at offset 2072283 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:39:06,372] INFO [ProducerStateManager partition=__consumer_offsets-24] Wrote producer snapshot at offset 1 with 0 producer ids in 0 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:39:06,382] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 11:39:06,392] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:39:06,393] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:39:06,393] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:39:06,393] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:39:06,397] WARN An exception was thrown while closing send thread for session 0x10000e86ba00000. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x10000e86ba00000, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 11:39:06,413] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:06,413] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:06,414] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:06,498] INFO Session: 0x10000e86ba00000 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:06,498] INFO EventThread shut down for session: 0x10000e86ba00000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:39:06,501] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:39:06,501] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:06,629] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:06,629] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:06,629] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:07,404] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:07,404] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:07,406] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 11:39:07,439] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 11:39:07,440] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:39:07,440] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:39:07,440] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:39:07,443] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 11:39:07,444] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:39:07,445] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-04 11:39:07,623] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:07,623] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:07,624] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:07,638] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:07,638] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:07,639] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:07,646] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:07,646] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:07,648] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 11:39:07,706] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 11:39:07,706] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:39:07,707] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:39:07,707] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:39:07,711] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 11:39:07,712] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:39:07,713] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-04 11:39:18,781] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:39:18,783] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:39:18,792] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:39:18,792] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:39:18,792] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:39:18,792] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:39:18,798] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:39:18,798] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:39:18,798] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:39:18,799] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-04 11:39:18,807] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-04 11:39:18,837] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:39:18,838] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:39:18,839] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:39:18,839] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:39:18,840] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:39:18,840] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:39:18,840] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-04 11:39:18,859] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@ca263c2 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-04 11:39:18,869] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:39:18,882] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,883] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,883] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,883] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,883] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,883] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,883] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,883] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,883] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,884] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,887] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,887] INFO Server environment:host.name=fedora (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,888] INFO Server environment:java.version=16.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,888] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,888] INFO Server environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,888] INFO Server environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,888] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,888] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,889] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,889] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,889] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,889] INFO Server environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,889] INFO Server environment:user.name=della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,889] INFO Server environment:user.home=/home/della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,889] INFO Server environment:user.dir=/home/della/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,889] INFO Server environment:os.memory.free=495MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,889] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,889] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,890] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,890] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,890] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,890] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,890] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,890] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,891] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,894] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-04 11:39:18,897] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,897] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,900] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:39:18,901] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:39:18,903] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:39:18,903] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:39:18,903] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:39:18,903] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:39:18,905] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:39:18,905] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:39:18,909] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,909] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,910] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:18,929] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:39:18,930] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:39:18,933] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:39:18,939] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:39:18,962] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:39:18,963] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:39:18,963] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:39:18,963] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:39:18,971] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-04 11:39:18,973] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.2a0 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-05-04 11:39:18,994] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x2a0, and digest value as 296726674909 (org.apache.zookeeper.server.DataTree)
[2022-05-04 11:39:19,053] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-04 11:39:19,061] INFO 141 txns loaded in 52 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:39:19,061] INFO Snapshot loaded in 97 ms, highest zxid is 0x32d, digest is 302046524482 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:39:19,061] INFO Snapshotting: 0x32d to /tmp/zookeeper/version-2/snapshot.32d (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:39:19,069] INFO Snapshot taken in 8 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:39:19,087] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-04 11:39:19,088] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-04 11:39:19,129] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-04 11:39:33,749] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:39:34,383] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:39:34,581] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:39:34,591] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:39:34,593] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:39:34,645] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:39:34,665] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,665] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,669] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,669] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,670] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,670] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,670] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,670] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,670] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,671] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,671] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,671] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,671] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,671] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,671] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,671] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,671] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,672] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,677] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:34,699] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:39:34,716] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:39:34,728] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:39:34,733] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:39:34,734] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:39:34,743] INFO Socket connection established, initiating session, client: /127.0.0.1:42604, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:39:34,761] INFO Creating new log file: log.32e (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-04 11:39:34,780] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10000f1427e0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:39:34,793] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:39:34,999] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:39:35,320] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:39:35,335] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:39:35,352] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:39:35,455] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:39:35,483] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:39:35,587] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:35,590] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:35,593] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:35,602] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:35,645] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:39:35,749] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 11:39:35,767] INFO Attempting recovery for all logs in /tmp/kafka-logs-1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:39:35,792] INFO Loaded 0 logs in 42ms. (kafka.log.LogManager)
[2022-05-04 11:39:35,794] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:39:35,800] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:39:36,568] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:37,109] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:39:37,526] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:39:37,532] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-04 11:39:37,619] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:39:37,660] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:37,689] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:37,694] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:37,696] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:37,698] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:37,736] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:39:37,820] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:39:37,858] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:39:37,903] INFO Stat of the created znode at /brokers/ids/1 is: 829,829,1651657177888,1651657177888,1,0,0,72058630240600064,196,0,829
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:39:37,905] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://fedora:9092, czxid (broker epoch): 829 (kafka.zk.KafkaZkClient)
[2022-05-04 11:39:38,032] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:39:38,048] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:39:38,061] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:39:38,104] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:38,120] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:38,121] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:39:38,132] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:38,142] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,142] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,142] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,142] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,142] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,143] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,143] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,143] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,143] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,143] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,143] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,143] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,143] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,143] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,144] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,144] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,144] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,144] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,153] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:39:38,196] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:39:38,217] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:39:38,225] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:39:38,226] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:38,269] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:39:38,269] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:39:38,288] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:40470, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:39:38,309] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10000f1427e0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:39:38,322] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:39:38,386] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:38,464] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:39:38,509] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:39:38,517] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:39:38,574] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:39:38,657] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:38,821] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:39:38,906] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:39:38,944] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:39:38,959] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:39:39,011] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:39:39,079] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:39:39,080] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:39:39,090] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:39:39,090] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:39:39,090] INFO Kafka startTimeMs: 1651657179080 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:39:39,094] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-04 11:39:39,123] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:39:39,180] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:39:39,291] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:39,297] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:39,326] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:39,330] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:39,334] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:39,342] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:39:39,384] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:39:39,468] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 11:39:39,482] INFO Attempting recovery for all logs in /tmp/kafka-logs-2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:39:39,515] INFO Loaded 0 logs in 45ms. (kafka.log.LogManager)
[2022-05-04 11:39:39,519] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:39:39,528] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:39:40,054] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, provatop-0, __consumer_offsets-46, output-0, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-48, __consumer_offsets-12, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-8, __consumer_offsets-4, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:39:40,301] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:40,362] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,417] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-1/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,421] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-04 11:39:40,424] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,475] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,481] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-1/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,482] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-04 11:39:40,482] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,494] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,503] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-1/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,503] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-04 11:39:40,503] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,517] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,526] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-1/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,527] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-04 11:39:40,527] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,552] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,562] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-1/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,562] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-04 11:39:40,562] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,589] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,600] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-1/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,601] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-04 11:39:40,601] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,618] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,626] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-1/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,626] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-04 11:39:40,627] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,675] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,677] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-1/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,677] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-04 11:39:40,677] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,687] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,691] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-1/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,693] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-04 11:39:40,693] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,700] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,701] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-1/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,702] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-04 11:39:40,702] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,728] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,730] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-1/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,731] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-04 11:39:40,731] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,746] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,749] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-1/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,752] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-04 11:39:40,752] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,771] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,781] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-1/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,782] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,783] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,793] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,795] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-1/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,795] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-04 11:39:40,795] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,815] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,820] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-1/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,821] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-04 11:39:40,821] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,832] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,835] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-1/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,835] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-04 11:39:40,835] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,846] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,853] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-1/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,853] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-04 11:39:40,853] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,862] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,873] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-1/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,873] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-04 11:39:40,874] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,893] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,906] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-1/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,906] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-04 11:39:40,906] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,913] INFO [LogLoader partition=output-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,915] INFO Created log for partition output-0 in /tmp/kafka-logs-1/output-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:39:40,915] INFO [Partition output-0 broker=1] No checkpointed highwatermark is found for partition output-0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,916] INFO [Partition output-0 broker=1] Log loaded for partition output-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,936] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,943] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-1/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,943] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-04 11:39:40,943] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:40,964] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:40,973] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-1/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:40,974] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-04 11:39:40,974] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:41,013] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:41,019] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-1/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:41,019] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-04 11:39:41,019] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:41,064] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:41,070] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-1/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:41,070] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-04 11:39:41,070] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:41,080] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:39:41,099] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:41,101] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-04 11:39:41,107] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-1/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:41,108] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-04 11:39:41,108] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:41,139] INFO [LogLoader partition=provatop-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:41,143] INFO Created log for partition provatop-0 in /tmp/kafka-logs-1/provatop-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:39:41,143] INFO [Partition provatop-0 broker=1] No checkpointed highwatermark is found for partition provatop-0 (kafka.cluster.Partition)
[2022-05-04 11:39:41,144] INFO [Partition provatop-0 broker=1] Log loaded for partition provatop-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:41,155] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:41,159] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-1/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:41,160] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-04 11:39:41,160] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:41,204] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,213] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,224] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:39:41,230] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,230] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,230] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,231] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,232] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,232] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,233] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,233] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,233] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,233] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,233] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,233] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,234] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,234] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,234] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,234] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,234] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,234] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,234] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,234] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,235] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,235] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,235] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,235] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,235] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,235] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,235] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,235] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,235] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,235] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,235] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,236] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,237] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,237] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,237] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,238] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,238] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,238] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,238] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,238] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,240] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,241] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,241] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,241] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,242] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,242] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,242] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,242] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,258] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 35 milliseconds for epoch 4, of which 24 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,259] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 29 milliseconds for epoch 4, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,260] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 28 milliseconds for epoch 4, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,260] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 28 milliseconds for epoch 4, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,260] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 27 milliseconds for epoch 4, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,261] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 28 milliseconds for epoch 4, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,261] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 28 milliseconds for epoch 4, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,262] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 28 milliseconds for epoch 4, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,262] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 28 milliseconds for epoch 4, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,263] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 29 milliseconds for epoch 4, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,263] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 29 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,264] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 29 milliseconds for epoch 4, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,264] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 29 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,264] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 29 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,265] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 30 milliseconds for epoch 4, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,265] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 30 milliseconds for epoch 4, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,266] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 30 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,267] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:41,267] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 30 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,268] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 30 milliseconds for epoch 4, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,269] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 31 milliseconds for epoch 4, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,270] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 30 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,270] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 29 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,271] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 30 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,272] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 30 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,273] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 31 milliseconds for epoch 4, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:41,327] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:41,333] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:41,358] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:41,365] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:41,400] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group console-consumer-43781 in Empty state. Created a new member id console-consumer-321201f6-c1e9-4963-9dfb-f65110f15b35 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,421] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:39:41,465] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-43781 in state PreparingRebalance with old generation 0 (__consumer_offsets-24) (reason: Adding new member console-consumer-321201f6-c1e9-4963-9dfb-f65110f15b35 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,507] INFO [GroupCoordinator 1]: Stabilized group console-consumer-43781 generation 1 (__consumer_offsets-24) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,565] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:39:41,615] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-321201f6-c1e9-4963-9dfb-f65110f15b35 for group console-consumer-43781 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,621] INFO Stat of the created znode at /brokers/ids/2 is: 873,873,1651657181589,1651657181589,1,0,0,72058630240600065,196,0,873
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:39:41,623] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://fedora:9093, czxid (broker epoch): 873 (kafka.zk.KafkaZkClient)
[2022-05-04 11:39:41,779] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:41,794] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:41,819] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:41,828] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,899] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:41,964] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:39:41,989] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:39:41,989] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:39:42,066] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:39:42,147] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:39:42,233] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:39:42,295] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:39:42,296] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:39:42,330] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:39:42,330] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:39:42,331] INFO Kafka startTimeMs: 1651657182297 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:39:42,341] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-04 11:39:42,599] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:42,599] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:39:42,805] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:42,848] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-2/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:42,852] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-04 11:39:42,864] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:42,872] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:42,882] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-2/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:42,882] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-04 11:39:42,883] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:42,894] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:42,907] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-2/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:42,907] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-04 11:39:42,907] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:42,918] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:42,923] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-2/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:42,923] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-04 11:39:42,924] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:42,931] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:42,933] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-2/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:42,934] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-04 11:39:42,935] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:42,941] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:42,943] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-2/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:42,944] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-04 11:39:42,944] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:42,953] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:42,955] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-2/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:42,955] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-04 11:39:42,956] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:42,962] INFO [LogLoader partition=input-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:42,964] INFO Created log for partition input-0 in /tmp/kafka-logs-2/input-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:39:42,965] INFO [Partition input-0 broker=2] No checkpointed highwatermark is found for partition input-0 (kafka.cluster.Partition)
[2022-05-04 11:39:42,965] INFO [Partition input-0 broker=2] Log loaded for partition input-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:42,972] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:42,974] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-2/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:42,974] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-04 11:39:42,975] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:42,981] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:42,984] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-2/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:42,984] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-04 11:39:42,985] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:42,993] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:42,994] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-2/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:42,994] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-04 11:39:42,994] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:42,999] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,002] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-2/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,002] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-04 11:39:43,003] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,012] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,015] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-2/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,015] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-04 11:39:43,016] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,023] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,028] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-2/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,028] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-04 11:39:43,028] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,045] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,047] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-2/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,048] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-04 11:39:43,048] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,056] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,058] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-2/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,059] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-04 11:39:43,059] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,065] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,069] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-2/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,070] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-04 11:39:43,070] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,078] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,080] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-2/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,080] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-04 11:39:43,080] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,089] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,092] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-2/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,092] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-04 11:39:43,093] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,098] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,102] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-2/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,103] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-04 11:39:43,103] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,111] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,116] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-2/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,116] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-04 11:39:43,116] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,129] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,132] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-2/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,132] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-04 11:39:43,132] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,141] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,144] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-2/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,144] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-04 11:39:43,144] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,152] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,155] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-2/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,155] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-04 11:39:43,156] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,162] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,164] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-2/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,165] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-04 11:39:43,165] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,190] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:39:43,193] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-2/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:39:43,193] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-04 11:39:43,194] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:39:43,253] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, input-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:39:43,310] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 3 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,312] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,315] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,315] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,316] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,316] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,316] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,316] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,316] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,316] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,316] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 33 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,317] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,317] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,317] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,317] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,317] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,317] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,318] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,318] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 45 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,318] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,318] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,318] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,319] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,319] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,319] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,319] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,319] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,319] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,319] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 39 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,319] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,319] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 9 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,319] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,320] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 27 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,320] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,320] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,320] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,320] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,320] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,320] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 21 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,320] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,321] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,321] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,321] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,321] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,324] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,325] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,325] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,325] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,325] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:39:43,325] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,344] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 29 milliseconds for epoch 14, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,344] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 29 milliseconds for epoch 14, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,345] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 29 milliseconds for epoch 14, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,345] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 29 milliseconds for epoch 14, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,346] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 30 milliseconds for epoch 14, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,346] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 29 milliseconds for epoch 14, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,347] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 30 milliseconds for epoch 14, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,347] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 30 milliseconds for epoch 14, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,348] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 30 milliseconds for epoch 14, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,348] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 30 milliseconds for epoch 14, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,349] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 30 milliseconds for epoch 14, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,349] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 30 milliseconds for epoch 14, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,350] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 31 milliseconds for epoch 14, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,352] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 33 milliseconds for epoch 14, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,352] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 33 milliseconds for epoch 14, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,353] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 34 milliseconds for epoch 14, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,353] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 33 milliseconds for epoch 14, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,354] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 34 milliseconds for epoch 14, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,355] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 35 milliseconds for epoch 14, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,360] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 39 milliseconds for epoch 14, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,360] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 39 milliseconds for epoch 14, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,361] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 39 milliseconds for epoch 14, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,361] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 36 milliseconds for epoch 14, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,361] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 36 milliseconds for epoch 14, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:39:43,362] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 37 milliseconds for epoch 14, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:40:08,672] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-43781 in state PreparingRebalance with old generation 1 (__consumer_offsets-24) (reason: Removing member console-consumer-321201f6-c1e9-4963-9dfb-f65110f15b35 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:40:08,676] INFO [GroupCoordinator 1]: Group console-consumer-43781 with generation 2 is now empty (__consumer_offsets-24) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:40:08,680] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=console-consumer-321201f6-c1e9-4963-9dfb-f65110f15b35, groupInstanceId=None, clientId=console-consumer, clientHost=/192.168.1.114, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-43781 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:40:17,773] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-2d347a53-4546-44ac-b7a3-b69c500dd050 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:40:17,815] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member rdkafka-2d347a53-4546-44ac-b7a3-b69c500dd050 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:40:17,846] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 1 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:40:17,906] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-2d347a53-4546-44ac-b7a3-b69c500dd050 for group gruppo for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:41:17,692] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: Removing member rdkafka-2d347a53-4546-44ac-b7a3-b69c500dd050 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:41:17,694] INFO [GroupCoordinator 2]: Group gruppo with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:41:17,696] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-2d347a53-4546-44ac-b7a3-b69c500dd050, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.1.114, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:41:44,642] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:41:44,644] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-04 11:41:44,645] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 11:41:44,674] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-04 11:41:44,681] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:41:44,682] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:41:44,683] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:41:44,685] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:41:44,695] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:41:44,696] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:41:44,698] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:41:44,702] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:44,804] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:44,804] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:44,805] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 11:41:44,807] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:44,870] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:44,871] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:44,874] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:41:44,876] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 11:41:44,876] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:41:44,876] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:41:44,876] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:41:44,878] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:41:44,879] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:41:44,879] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:44,930] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:44,930] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:44,931] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,070] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,070] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,073] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:41:45,074] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 11:41:45,074] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:41:45,075] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:41:45,075] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:41:45,075] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:41:45,077] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:41:45,078] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:41:45,078] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:41:45,078] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,182] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,182] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,183] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,269] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,269] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,270] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,277] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,277] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,278] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,279] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,279] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:45,280] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 11:41:45,281] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:41:45,281] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:41:45,281] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:41:45,285] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:41:45,286] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:41:45,286] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:41:45,286] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:41:45,287] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:41:45,288] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 11:41:45,318] INFO [ProducerStateManager partition=output-0] Wrote producer snapshot at offset 607073 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:41:45,320] INFO [ProducerStateManager partition=__consumer_offsets-24] Wrote producer snapshot at offset 2 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:41:45,329] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 11:41:45,342] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:41:45,342] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:41:45,342] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:41:45,343] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:41:45,447] INFO Session: 0x10000f1427e0000 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:41:45,448] INFO EventThread shut down for session: 0x10000f1427e0000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:41:45,449] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:41:45,450] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:45,615] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:45,615] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:45,615] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:45,641] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:45,641] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:45,643] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:46,440] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:41:46,442] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-04 11:41:46,443] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 11:41:46,463] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2022-05-04 11:41:46,470] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:41:46,471] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:41:46,471] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:41:46,472] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:41:46,480] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:41:46,481] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:41:46,484] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:41:46,488] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:46,642] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:46,642] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:46,642] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:46,643] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:46,643] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:46,646] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 11:41:46,673] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:46,673] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:46,675] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 11:41:46,677] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:46,689] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 11:41:46,692] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:41:46,692] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:41:46,692] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:41:46,695] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 11:41:46,697] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:41:46,697] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-04 11:41:46,720] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:46,720] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:46,725] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:41:46,726] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 11:41:46,726] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:41:46,726] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:41:46,726] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:41:46,727] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:41:46,728] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:41:46,729] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:46,881] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:46,881] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:46,882] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:46,940] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:46,940] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:46,942] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:41:46,944] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 11:41:46,945] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:41:46,945] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:41:46,945] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:41:46,946] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:41:46,948] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:41:46,949] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:41:46,950] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:41:46,950] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:47,116] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:47,116] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:47,116] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:47,272] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:47,272] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:47,273] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:47,289] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:47,289] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:47,290] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:47,324] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:47,324] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:41:47,330] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 11:41:47,331] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:41:47,332] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:41:47,332] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:41:47,337] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:41:47,337] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:41:47,338] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:41:47,338] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:41:47,339] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:41:47,340] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 11:41:47,362] INFO [ProducerStateManager partition=__consumer_offsets-37] Wrote producer snapshot at offset 14 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:41:47,367] INFO [ProducerStateManager partition=input-0] Wrote producer snapshot at offset 13664381 with 0 producer ids in 0 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:41:47,373] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 11:41:47,381] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:41:47,381] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:41:47,381] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:41:47,382] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:41:47,385] WARN An exception was thrown while closing send thread for session 0x10000f1427e0001. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x10000f1427e0001, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 11:41:47,489] INFO EventThread shut down for session: 0x10000f1427e0001 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:41:47,489] INFO Session: 0x10000f1427e0001 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:41:47,491] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:41:47,492] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:48,361] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:48,361] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:48,362] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:48,366] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:48,366] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:48,367] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:49,367] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:49,367] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:49,367] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:49,368] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:49,368] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:41:49,372] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 11:41:49,429] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 11:41:49,430] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:41:49,430] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:41:49,430] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:41:49,434] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 11:41:49,436] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:41:49,436] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-04 11:42:04,697] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:42:04,700] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:42:04,707] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:42:04,708] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:42:04,708] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:42:04,708] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:42:04,710] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:42:04,710] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:42:04,710] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:42:04,711] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-04 11:42:04,715] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-04 11:42:04,737] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:42:04,738] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:42:04,740] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:42:04,740] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:42:04,740] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:42:04,740] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:42:04,741] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-04 11:42:04,761] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@ca263c2 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-04 11:42:04,768] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:42:04,789] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,789] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,789] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,789] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,789] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,789] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,789] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,789] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,790] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,790] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,794] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,794] INFO Server environment:host.name=fedora (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,795] INFO Server environment:java.version=16.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,795] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,795] INFO Server environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,795] INFO Server environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,795] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,796] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,796] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,796] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,796] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,796] INFO Server environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,796] INFO Server environment:user.name=della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,796] INFO Server environment:user.home=/home/della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,796] INFO Server environment:user.dir=/home/della/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,796] INFO Server environment:os.memory.free=495MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,796] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,796] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,797] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,797] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,797] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,797] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,797] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,797] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,798] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,799] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-04 11:42:04,803] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,803] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,806] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:42:04,807] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:42:04,810] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:42:04,810] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:42:04,810] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:42:04,810] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:42:04,810] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:42:04,810] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:42:04,813] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,813] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,813] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,829] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:42:04,830] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:42:04,832] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:42:04,839] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:42:04,860] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:42:04,860] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:42:04,860] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:42:04,861] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:42:04,868] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-04 11:42:04,869] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.32d (org.apache.zookeeper.server.persistence.FileSnap)
[2022-05-04 11:42:04,892] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x32d, and digest value as 302046524482 (org.apache.zookeeper.server.DataTree)
[2022-05-04 11:42:04,946] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-04 11:42:04,957] INFO 117 txns loaded in 46 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:42:04,957] INFO Snapshot loaded in 96 ms, highest zxid is 0x3a2, digest is 317490631857 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:42:04,957] INFO Snapshotting: 0x3a2 to /tmp/zookeeper/version-2/snapshot.3a2 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:42:04,964] INFO Snapshot taken in 6 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:42:04,984] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-04 11:42:04,985] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-04 11:42:05,021] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-04 11:42:36,157] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:42:36,495] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:42:36,651] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:42:36,658] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:42:36,659] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:42:36,683] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:42:36,695] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,695] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,695] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,695] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,695] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,695] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,696] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,696] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,696] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,696] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,696] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,696] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,696] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,696] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,696] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,697] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,697] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,697] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,700] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:36,712] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:42:36,721] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:42:36,725] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:42:36,730] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:42:36,730] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:42:36,736] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:40472, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:42:36,749] INFO Creating new log file: log.3a3 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-04 11:42:36,761] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10000f3ca860000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:42:36,766] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:42:36,889] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:42:37,152] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:42:37,162] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:42:37,173] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:42:37,259] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:42:37,280] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:42:37,363] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:42:37,365] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:42:37,369] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:42:37,373] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:42:37,402] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:42:37,462] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 11:42:37,472] INFO Attempting recovery for all logs in /tmp/kafka-logs-1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:42:37,485] INFO Loaded 0 logs in 22ms. (kafka.log.LogManager)
[2022-05-04 11:42:37,486] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:42:37,495] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:42:38,140] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:42:38,284] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:42:38,768] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:42:38,775] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-04 11:42:38,843] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:42:38,867] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:42:38,896] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:38,905] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:38,908] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:38,910] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:38,933] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:42:38,950] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:42:39,035] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:42:39,071] INFO Stat of the created znode at /brokers/ids/1 is: 946,946,1651657359057,1651657359057,1,0,0,72058641112760320,196,0,946
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:42:39,073] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://fedora:9092, czxid (broker epoch): 946 (kafka.zk.KafkaZkClient)
[2022-05-04 11:42:39,106] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:42:39,113] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:42:39,114] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:42:39,144] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:42:39,156] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,156] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,156] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,156] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,157] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,157] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,157] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,157] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,157] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,158] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,158] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,158] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,158] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,158] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,159] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,159] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,159] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,159] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,163] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:42:39,199] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:42:39,213] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:42:39,213] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:39,225] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:42:39,231] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:39,236] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:42:39,237] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:42:39,244] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:40474, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:42:39,248] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:39,259] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10000f3ca860001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:42:39,265] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:42:39,276] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:39,316] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:39,374] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:42:39,390] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:42:39,394] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:42:39,429] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:42:39,480] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:39,547] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:42:39,613] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:42:39,627] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:42:39,628] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:42:39,640] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:42:39,641] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:42:39,648] INFO Kafka startTimeMs: 1651657359628 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:42:39,650] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-04 11:42:39,785] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:42:39,810] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:42:39,818] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:42:39,885] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:42:39,892] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:42:39,944] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:42:39,960] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:42:40,049] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:42:40,050] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:42:40,051] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:42:40,057] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:42:40,091] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:42:40,172] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 11:42:40,187] INFO Attempting recovery for all logs in /tmp/kafka-logs-2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:42:40,220] INFO Loaded 0 logs in 47ms. (kafka.log.LogManager)
[2022-05-04 11:42:40,221] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:42:40,231] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:42:40,356] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,384] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-1/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,388] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-04 11:42:40,390] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,397] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,400] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-1/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,401] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-04 11:42:40,401] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,413] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,418] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-1/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,419] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-04 11:42:40,419] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,441] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,445] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-1/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,445] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-04 11:42:40,446] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,470] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,474] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-1/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,475] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-04 11:42:40,475] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,490] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,492] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-1/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,493] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-04 11:42:40,493] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,514] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,520] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-1/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,520] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-04 11:42:40,520] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,531] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,555] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-1/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,556] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-04 11:42:40,556] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,568] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,571] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-1/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,571] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-04 11:42:40,572] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,591] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,593] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-1/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,594] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-04 11:42:40,594] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,602] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,605] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-1/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,605] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-04 11:42:40,605] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,612] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,614] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-1/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,614] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-04 11:42:40,615] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,624] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,627] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-1/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,627] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,628] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,640] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,644] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-1/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,644] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-04 11:42:40,645] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,661] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,671] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-1/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,672] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-04 11:42:40,672] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,685] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,687] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-1/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,688] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-04 11:42:40,688] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,697] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,700] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-1/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,701] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-04 11:42:40,702] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,718] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,721] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-1/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,722] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-04 11:42:40,722] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,731] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,742] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-1/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,742] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-04 11:42:40,742] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,752] INFO [LogLoader partition=output-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,756] INFO Created log for partition output-0 in /tmp/kafka-logs-1/output-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:42:40,757] INFO [Partition output-0 broker=1] No checkpointed highwatermark is found for partition output-0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,758] INFO [Partition output-0 broker=1] Log loaded for partition output-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,781] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,784] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-1/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,785] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-04 11:42:40,785] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,793] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,795] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-1/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,795] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-04 11:42:40,795] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,803] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,807] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-1/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,808] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-04 11:42:40,808] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,819] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,822] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-1/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,823] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-04 11:42:40,823] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,830] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,842] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-1/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,842] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-04 11:42:40,843] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,857] INFO [LogLoader partition=provatop-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,858] INFO Created log for partition provatop-0 in /tmp/kafka-logs-1/provatop-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:42:40,859] INFO [Partition provatop-0 broker=1] No checkpointed highwatermark is found for partition provatop-0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,859] INFO [Partition provatop-0 broker=1] Log loaded for partition provatop-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,865] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:40,870] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-1/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:40,870] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-04 11:42:40,870] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:40,929] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, provatop-0, __consumer_offsets-46, output-0, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-48, __consumer_offsets-12, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-8, __consumer_offsets-4, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:42:40,959] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:42:40,998] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,000] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,015] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,015] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,015] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,015] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,015] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,015] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,016] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,016] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,016] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,019] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,023] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,024] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,024] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,024] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,024] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,024] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,024] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,024] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,024] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,024] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,024] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,024] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,025] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,025] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,025] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,025] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,025] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,026] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,026] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,026] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,026] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,026] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,026] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,026] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,026] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,026] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,019] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 12 milliseconds for epoch 6, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,029] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 14 milliseconds for epoch 6, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,030] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 15 milliseconds for epoch 6, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,030] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 15 milliseconds for epoch 6, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,031] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 14 milliseconds for epoch 6, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,031] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 8 milliseconds for epoch 6, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,031] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 7 milliseconds for epoch 6, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,032] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 8 milliseconds for epoch 6, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,036] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,036] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,036] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,036] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,037] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,037] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,037] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,037] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,037] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,039] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,039] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,039] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,039] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 13 milliseconds for epoch 6, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,042] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 18 milliseconds for epoch 6, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,042] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 18 milliseconds for epoch 6, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,043] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 19 milliseconds for epoch 6, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,043] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 18 milliseconds for epoch 6, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,044] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 18 milliseconds for epoch 6, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,060] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 34 milliseconds for epoch 6, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,060] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 34 milliseconds for epoch 6, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,061] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 35 milliseconds for epoch 6, of which 35 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,061] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 35 milliseconds for epoch 6, of which 35 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,062] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 36 milliseconds for epoch 6, of which 35 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,062] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 26 milliseconds for epoch 6, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,062] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 26 milliseconds for epoch 6, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,064] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 27 milliseconds for epoch 6, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,065] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 28 milliseconds for epoch 6, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,068] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 29 milliseconds for epoch 6, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,071] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 30 milliseconds for epoch 6, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:41,438] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:42:41,445] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-04 11:42:41,513] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:42:41,532] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:42:41,556] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:41,558] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:41,560] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:41,561] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:41,583] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:42:41,673] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:42:41,697] INFO Stat of the created znode at /brokers/ids/2 is: 1017,1017,1651657361688,1651657361688,1,0,0,72058641112760321,196,0,1017
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:42:41,701] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://fedora:9093, czxid (broker epoch): 1017 (kafka.zk.KafkaZkClient)
[2022-05-04 11:42:41,841] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:41,856] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:41,862] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:41,883] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,902] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:41,930] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:42:41,937] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:42:41,938] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:42:41,978] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:42:42,004] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:42:42,050] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:42:42,058] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:42:42,060] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:42:42,074] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:42:42,074] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:42:42,074] INFO Kafka startTimeMs: 1651657362060 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:42:42,078] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-04 11:42:42,158] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:42:42,190] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:42:42,343] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,380] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-2/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,384] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-04 11:42:42,386] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,393] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,395] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-2/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,396] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-04 11:42:42,396] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,407] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,411] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-2/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,411] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-04 11:42:42,411] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,420] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,422] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-2/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,422] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-04 11:42:42,422] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,430] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,431] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-2/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,432] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-04 11:42:42,432] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,440] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,442] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-2/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,442] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-04 11:42:42,443] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,449] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,451] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-2/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,451] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-04 11:42:42,451] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,456] INFO [LogLoader partition=input-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,457] INFO Created log for partition input-0 in /tmp/kafka-logs-2/input-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:42:42,458] INFO [Partition input-0 broker=2] No checkpointed highwatermark is found for partition input-0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,458] INFO [Partition input-0 broker=2] Log loaded for partition input-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,463] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,465] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-2/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,465] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-04 11:42:42,465] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,471] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,472] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-2/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,472] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-04 11:42:42,472] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,478] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,479] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-2/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,480] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-04 11:42:42,480] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,485] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,487] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-2/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,487] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-04 11:42:42,487] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,492] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,493] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-2/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,494] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-04 11:42:42,494] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,498] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,500] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-2/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,501] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-04 11:42:42,501] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,506] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,507] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-2/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,507] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-04 11:42:42,507] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,513] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,514] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-2/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,514] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-04 11:42:42,514] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,521] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,522] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-2/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,522] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-04 11:42:42,522] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,526] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,527] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-2/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,528] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-04 11:42:42,528] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,532] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,534] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-2/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,534] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-04 11:42:42,534] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,539] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,540] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-2/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,540] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-04 11:42:42,540] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,544] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,545] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-2/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,545] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-04 11:42:42,545] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,551] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,553] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-2/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,553] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-04 11:42:42,553] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,558] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,559] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-2/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,559] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-04 11:42:42,559] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,564] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,565] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-2/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,565] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-04 11:42:42,565] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,571] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,572] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-2/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,572] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-04 11:42:42,572] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,576] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:42:42,577] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-2/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:42:42,577] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-04 11:42:42,577] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:42:42,609] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, input-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:42:42,655] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 3 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,656] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,659] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,660] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,660] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,660] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,660] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,660] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,660] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,660] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,660] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 33 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,660] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,661] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,661] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,661] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,661] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,661] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,661] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,661] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 45 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,661] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,661] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,661] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,661] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,662] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,662] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,662] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,662] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,662] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,662] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 39 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,662] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,662] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 9 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,662] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,662] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 27 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,662] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,662] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,663] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,663] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,663] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,663] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 21 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,663] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,663] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,663] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,663] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,663] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,663] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,664] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,664] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,664] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,664] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:42,664] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,674] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 15 milliseconds for epoch 16, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,675] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 15 milliseconds for epoch 16, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,675] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 15 milliseconds for epoch 16, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,676] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 16 milliseconds for epoch 16, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,676] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 16 milliseconds for epoch 16, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,677] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 17 milliseconds for epoch 16, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,677] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 16 milliseconds for epoch 16, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,678] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 17 milliseconds for epoch 16, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,678] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 17 milliseconds for epoch 16, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,678] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 17 milliseconds for epoch 16, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,679] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 18 milliseconds for epoch 16, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,679] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 17 milliseconds for epoch 16, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,680] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 18 milliseconds for epoch 16, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,680] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 18 milliseconds for epoch 16, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,681] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 18 milliseconds for epoch 16, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,681] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 19 milliseconds for epoch 16, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,681] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 19 milliseconds for epoch 16, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,682] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 19 milliseconds for epoch 16, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,682] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 19 milliseconds for epoch 16, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,682] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 19 milliseconds for epoch 16, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,683] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 20 milliseconds for epoch 16, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,684] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 21 milliseconds for epoch 16, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,684] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 20 milliseconds for epoch 16, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,685] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 20 milliseconds for epoch 16, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:42,685] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 21 milliseconds for epoch 16, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:42:47,251] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-9ac42105-c23a-439d-8204-09eda9f58876 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:47,278] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member rdkafka-9ac42105-c23a-439d-8204-09eda9f58876 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:47,303] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 1 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:42:47,329] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-9ac42105-c23a-439d-8204-09eda9f58876 for group gruppo for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:43:47,190] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: Removing member rdkafka-9ac42105-c23a-439d-8204-09eda9f58876 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:43:47,194] INFO [GroupCoordinator 2]: Group gruppo with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:43:47,196] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-9ac42105-c23a-439d-8204-09eda9f58876, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.1.114, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:43:57,238] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:43:57,240] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-04 11:43:57,241] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 11:43:57,265] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 14ms (kafka.server.KafkaServer)
[2022-05-04 11:43:57,274] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:43:57,275] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:43:57,275] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:43:57,276] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:43:57,286] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:43:57,288] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:43:57,291] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:43:57,293] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,363] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,363] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,364] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 11:43:57,365] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,503] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,503] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,507] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:43:57,508] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 11:43:57,508] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:43:57,508] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:43:57,508] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:43:57,509] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:43:57,510] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:43:57,510] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,532] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,532] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,534] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,734] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,734] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,736] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:43:57,738] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 11:43:57,739] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:43:57,739] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:43:57,739] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:43:57,740] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:43:57,741] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:43:57,742] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:43:57,742] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:43:57,742] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,814] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,814] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:57,815] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:58,000] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:43:58,002] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-04 11:43:58,003] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 11:43:58,013] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:58,013] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:58,014] INFO [KafkaServer id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-04 11:43:58,014] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:58,017] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:58,018] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:58,018] WARN [KafkaServer id=2] Connection to node 1 (fedora/192.168.1.114:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-04 11:43:58,019] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:58,019] WARN [KafkaServer id=2] Error during controlled shutdown, possibly because leader movement took longer than the configured controller.socket.timeout.ms and/or request.timeout.ms: Connection to fedora:9092 (id: 1 rack: null) failed. (kafka.server.KafkaServer)
[2022-05-04 11:43:58,022] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:58,022] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:43:58,025] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 11:43:58,026] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:43:58,026] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:43:58,026] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:43:58,029] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:43:58,030] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:43:58,030] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:43:58,030] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:43:58,031] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:43:58,032] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 11:43:58,068] INFO [ProducerStateManager partition=output-0] Wrote producer snapshot at offset 423441 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:43:58,080] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 11:43:58,098] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:43:58,099] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:43:58,099] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:43:58,100] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:43:58,112] WARN An exception was thrown while closing send thread for session 0x10000f3ca860000. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x10000f3ca860000, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 11:43:58,214] INFO EventThread shut down for session: 0x10000f3ca860000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:43:58,215] INFO Session: 0x10000f3ca860000 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:43:58,216] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:43:58,217] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:43:58,384] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:43:58,384] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:43:58,384] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:43:59,380] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:43:59,380] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:43:59,380] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:43:59,389] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:43:59,389] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:43:59,389] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:43:59,398] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:43:59,399] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:43:59,403] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 11:43:59,467] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 11:43:59,468] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:43:59,468] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:43:59,468] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:43:59,472] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 11:43:59,473] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:43:59,474] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-04 11:44:03,020] INFO [KafkaServer id=2] Retrying controlled shutdown (2 retries remaining) (kafka.server.KafkaServer)
[2022-05-04 11:44:03,020] INFO [KafkaServer id=2] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 11:44:03,030] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 9ms (kafka.server.KafkaServer)
[2022-05-04 11:44:03,039] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:44:03,040] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:44:03,040] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:44:03,041] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:44:03,053] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:44:03,054] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:44:03,056] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:44:03,059] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,101] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,101] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,103] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 11:44:03,105] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,174] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,174] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,177] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:44:03,178] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 11:44:03,178] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:44:03,178] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:44:03,178] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:44:03,179] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:44:03,179] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:03,180] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,280] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,280] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,281] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,406] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,406] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,407] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:03,408] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 11:44:03,409] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:44:03,409] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:44:03,409] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:44:03,410] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:44:03,411] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:44:03,411] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:44:03,412] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:44:03,412] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,606] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,606] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,607] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,675] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,675] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,676] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,701] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,702] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,702] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,901] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,901] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:03,905] ERROR Error while writing to checkpoint file /tmp/kafka-logs-2/replication-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.io.FileNotFoundException: /tmp/kafka-logs-2/replication-offset-checkpoint.tmp (No such file or directory)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:291)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:234)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:184)
	at org.apache.kafka.server.common.CheckpointFile.write(CheckpointFile.java:78)
	at kafka.server.checkpoints.CheckpointFileWithFailureHandler.write(CheckpointFileWithFailureHandler.scala:37)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:68)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7(ReplicaManager.scala:1875)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7$adapted(ReplicaManager.scala:1875)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6(ReplicaManager.scala:1875)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6$adapted(ReplicaManager.scala:1874)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:563)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:561)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:919)
	at scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:889)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1874)
	at kafka.server.ReplicaManager.shutdown(ReplicaManager.scala:1956)
	at kafka.server.KafkaServer.$anonfun$shutdown$16(KafkaServer.scala:747)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:747)
	at kafka.Kafka$.$anonfun$main$3(Kafka.scala:100)
	at kafka.utils.Exit$.$anonfun$addShutdownHook$1(Exit.scala:38)
	at java.base/java.lang.Thread.run(Thread.java:831)
[2022-05-04 11:44:03,909] ERROR [ReplicaManager broker=2] Error while writing to highwatermark file in directory /tmp/kafka-logs-2 (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file /tmp/kafka-logs-2/replication-offset-checkpoint
Caused by: java.io.FileNotFoundException: /tmp/kafka-logs-2/replication-offset-checkpoint.tmp (No such file or directory)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:291)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:234)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:184)
	at org.apache.kafka.server.common.CheckpointFile.write(CheckpointFile.java:78)
	at kafka.server.checkpoints.CheckpointFileWithFailureHandler.write(CheckpointFileWithFailureHandler.scala:37)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:68)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7(ReplicaManager.scala:1875)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7$adapted(ReplicaManager.scala:1875)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6(ReplicaManager.scala:1875)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6$adapted(ReplicaManager.scala:1874)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:563)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:561)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:919)
	at scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:889)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1874)
	at kafka.server.ReplicaManager.shutdown(ReplicaManager.scala:1956)
	at kafka.server.KafkaServer.$anonfun$shutdown$16(KafkaServer.scala:747)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:747)
	at kafka.Kafka$.$anonfun$main$3(Kafka.scala:100)
	at kafka.utils.Exit$.$anonfun$addShutdownHook$1(Exit.scala:38)
	at java.base/java.lang.Thread.run(Thread.java:831)
[2022-05-04 11:44:03,911] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 11:44:03,911] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:03,912] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:03,912] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:03,914] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:44:03,914] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:03,914] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:03,915] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:03,915] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:44:03,916] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 11:44:03,929] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,929] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,929] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,929] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,930] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,930] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,930] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,930] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,930] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,930] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,930] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,930] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,930] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,930] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,930] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,930] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,931] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,931] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,931] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,931] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,931] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,931] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,931] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,931] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,931] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,931] WARN There was an error in one of the threads during LogManager shutdown: org.apache.kafka.common.errors.KafkaStorageException: The log dir /tmp/kafka-logs-2 is already offline due to a previous IO exception. (kafka.log.LogManager)
[2022-05-04 11:44:03,934] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 11:44:03,950] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:44:03,951] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:44:03,951] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:44:03,952] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:44:03,955] WARN An exception was thrown while closing send thread for session 0x10000f3ca860001. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x10000f3ca860001, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 11:44:04,057] INFO EventThread shut down for session: 0x10000f3ca860001 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:44:04,057] INFO Session: 0x10000f3ca860001 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:04,059] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:44:04,060] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:04,066] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:04,066] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:04,066] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:05,066] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:05,066] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:05,066] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:06,066] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:06,066] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:06,067] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:06,072] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:06,072] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:06,073] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 11:44:06,147] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 11:44:06,148] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:44:06,149] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:44:06,149] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:44:06,151] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 11:44:06,152] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:44:06,153] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-04 11:44:10,574] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:44:10,577] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:44:10,584] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:44:10,584] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:44:10,584] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:44:10,584] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:44:10,588] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:44:10,588] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:44:10,588] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:44:10,588] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-04 11:44:10,597] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-04 11:44:10,621] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:44:10,621] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:44:10,622] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:44:10,622] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:44:10,623] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:44:10,623] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:44:10,623] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-04 11:44:10,643] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@ca263c2 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-04 11:44:10,650] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:44:10,668] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,668] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,669] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,669] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,669] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,669] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,669] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,669] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,669] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,669] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,673] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,674] INFO Server environment:host.name=fedora (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,674] INFO Server environment:java.version=16.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,674] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,675] INFO Server environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,675] INFO Server environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,675] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,675] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,675] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,676] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,676] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,676] INFO Server environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,676] INFO Server environment:user.name=della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,676] INFO Server environment:user.home=/home/della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,676] INFO Server environment:user.dir=/home/della/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,676] INFO Server environment:os.memory.free=495MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,676] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,676] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,676] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,676] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,676] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,677] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,677] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,677] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,677] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,679] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-04 11:44:10,681] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,681] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,684] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:44:10,685] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:44:10,687] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:44:10,687] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:44:10,687] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:44:10,688] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:44:10,688] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:44:10,688] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:44:10,692] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,692] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,692] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,709] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:44:10,710] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:44:10,712] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:44:10,718] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:44:10,739] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:44:10,739] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:44:10,740] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:44:10,740] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:44:10,747] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-04 11:44:10,748] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.3a2 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-05-04 11:44:10,764] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x3a2, and digest value as 317490631857 (org.apache.zookeeper.server.DataTree)
[2022-05-04 11:44:10,841] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-04 11:44:10,853] INFO 144 txns loaded in 71 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:44:10,854] INFO Snapshot loaded in 113 ms, highest zxid is 0x432, digest is 321570616548 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:44:10,854] INFO Snapshotting: 0x432 to /tmp/zookeeper/version-2/snapshot.432 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:44:10,860] INFO Snapshot taken in 6 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:44:10,878] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-04 11:44:10,879] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-04 11:44:10,915] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-04 11:44:29,506] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:44:29,892] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:44:30,056] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:44:30,064] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:44:30,065] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:44:30,094] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:44:30,103] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,103] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,103] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,103] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,103] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,104] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,104] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,105] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,105] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,105] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,105] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,105] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,106] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,106] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,106] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,106] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,106] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,106] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,109] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:30,122] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:44:30,131] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:44:30,136] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:44:30,144] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:44:30,145] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:44:30,153] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:40476, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:44:30,167] INFO Creating new log file: log.433 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-04 11:44:30,178] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10000f5b64d0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:44:30,186] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:44:30,340] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:44:30,624] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:44:30,636] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:44:30,644] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:44:30,721] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:44:30,739] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:44:30,760] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:44:30,812] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:30,814] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:30,815] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:30,829] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:30,853] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:44:30,909] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 11:44:30,919] INFO Attempting recovery for all logs in /tmp/kafka-logs-2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:44:30,933] INFO Loaded 0 logs in 24ms. (kafka.log.LogManager)
[2022-05-04 11:44:30,934] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:44:30,941] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:44:31,226] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:44:31,364] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:44:31,371] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:44:31,372] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:44:31,398] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:44:31,407] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,407] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,407] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,407] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,408] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,408] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,408] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,408] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,408] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,408] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,408] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,409] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,409] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,409] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,409] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,409] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,409] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,409] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,414] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:44:31,427] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:44:31,436] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:44:31,441] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:44:31,445] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:31,448] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:44:31,448] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:44:31,459] INFO Socket connection established, initiating session, client: /127.0.0.1:42606, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:44:31,467] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10000f5b64d0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:44:31,477] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:44:31,621] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:44:31,916] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:44:31,924] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:44:31,929] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-04 11:44:31,939] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:44:31,947] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:44:31,996] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:44:32,021] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:32,062] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:32,068] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:32,074] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:32,081] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:32,083] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:44:32,106] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:44:32,150] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:44:32,194] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:32,196] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:32,197] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:32,200] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:44:32,228] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:44:32,239] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:44:32,282] INFO Stat of the created znode at /brokers/ids/2 is: 1105,1105,1651657472270,1651657472270,1,0,0,72058649363415040,196,0,1105
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:44:32,283] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://fedora:9093, czxid (broker epoch): 1105 (kafka.zk.KafkaZkClient)
[2022-05-04 11:44:32,308] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 11:44:32,316] INFO Attempting recovery for all logs in /tmp/kafka-logs-1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:44:32,329] INFO Loaded 0 logs in 21ms. (kafka.log.LogManager)
[2022-05-04 11:44:32,330] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:44:32,336] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:44:32,401] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:32,402] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:32,409] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:32,440] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:32,512] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:32,561] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:44:32,579] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:44:32,580] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:44:32,651] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:32,747] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:44:32,795] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:44:32,827] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:44:32,828] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:44:32,845] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:44:32,846] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:44:32,846] INFO Kafka startTimeMs: 1651657472828 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:44:32,851] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-04 11:44:32,989] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker fedora:9093 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:33,027] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:33,031] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9093 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:33,371] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, input-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:44:33,670] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,716] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-2/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,722] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-04 11:44:33,724] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,756] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,763] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-2/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,764] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-04 11:44:33,764] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,778] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:44:33,785] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-04 11:44:33,789] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,792] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-2/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,792] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-04 11:44:33,792] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,804] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,809] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-2/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,810] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-04 11:44:33,811] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,825] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,827] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-2/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,828] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-04 11:44:33,828] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,837] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,840] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-2/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,840] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-04 11:44:33,840] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,857] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,863] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-2/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,863] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-04 11:44:33,864] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,877] INFO [LogLoader partition=input-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,882] INFO Created log for partition input-0 in /tmp/kafka-logs-2/input-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:44:33,882] INFO [Partition input-0 broker=2] No checkpointed highwatermark is found for partition input-0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,883] INFO [Partition input-0 broker=2] Log loaded for partition input-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,883] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:44:33,899] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,903] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:33,906] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-2/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,906] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-04 11:44:33,906] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,921] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,926] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-2/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,926] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-04 11:44:33,926] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,935] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,939] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-2/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,941] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-04 11:44:33,941] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,952] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,952] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:33,955] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-2/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,956] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-04 11:44:33,957] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,957] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:33,961] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:33,963] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:33,968] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,971] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-2/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,971] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-04 11:44:33,972] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,979] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,981] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-2/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,981] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-04 11:44:33,981] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:33,995] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:33,997] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-2/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:33,997] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-04 11:44:33,997] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,003] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:44:34,017] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,020] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-2/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,020] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-04 11:44:34,020] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,030] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,033] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-2/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,033] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-04 11:44:34,033] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,045] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,047] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-2/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,048] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-04 11:44:34,048] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,061] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,063] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-2/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,063] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-04 11:44:34,064] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,073] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,075] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-2/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,075] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-04 11:44:34,076] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,083] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,085] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-2/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,086] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-04 11:44:34,086] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,095] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,096] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-2/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,097] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-04 11:44:34,097] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,107] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,109] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-2/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,109] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-04 11:44:34,109] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,118] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,121] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-2/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,123] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-04 11:44:34,123] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,131] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,138] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-2/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,139] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-04 11:44:34,140] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,147] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:44:34,152] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,156] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-2/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,157] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-04 11:44:34,157] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,180] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 3 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,182] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,185] INFO Stat of the created znode at /brokers/ids/1 is: 1135,1135,1651657474169,1651657474169,1,0,0,72058649363415041,196,0,1135
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:44:34,186] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,187] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,187] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,187] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,188] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,188] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,189] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,189] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,190] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 33 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,190] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,190] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,191] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,191] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,191] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://fedora:9092, czxid (broker epoch): 1135 (kafka.zk.KafkaZkClient)
[2022-05-04 11:44:34,191] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,192] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,192] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,192] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 45 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,192] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,192] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,192] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,193] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,193] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,193] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,193] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,193] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,193] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,193] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 39 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,193] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,193] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 9 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,193] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,194] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 27 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,194] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,194] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,194] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,194] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,194] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,194] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 21 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,194] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,194] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,195] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,195] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,195] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,196] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,196] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,196] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,196] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,196] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,196] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,221] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 36 milliseconds for epoch 16, of which 24 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 39 milliseconds for epoch 16, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 38 milliseconds for epoch 16, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,227] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 38 milliseconds for epoch 16, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,228] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 38 milliseconds for epoch 16, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,229] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 39 milliseconds for epoch 16, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,230] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 39 milliseconds for epoch 16, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,231] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 40 milliseconds for epoch 16, of which 40 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,232] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 40 milliseconds for epoch 16, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,234] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 42 milliseconds for epoch 16, of which 42 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,235] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 43 milliseconds for epoch 16, of which 43 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,236] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 43 milliseconds for epoch 16, of which 42 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,237] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 43 milliseconds for epoch 16, of which 43 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,242] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 49 milliseconds for epoch 16, of which 49 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,243] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 50 milliseconds for epoch 16, of which 50 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,245] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 52 milliseconds for epoch 16, of which 51 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,245] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 51 milliseconds for epoch 16, of which 51 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,246] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 52 milliseconds for epoch 16, of which 52 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,247] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 53 milliseconds for epoch 16, of which 53 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,251] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 57 milliseconds for epoch 16, of which 56 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,252] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 57 milliseconds for epoch 16, of which 57 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,259] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 64 milliseconds for epoch 16, of which 63 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,262] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 66 milliseconds for epoch 16, of which 63 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,263] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 67 milliseconds for epoch 16, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,263] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 67 milliseconds for epoch 16, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:34,335] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:34,344] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:34,345] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:34,381] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,419] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:34,442] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:44:34,447] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:44:34,447] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:44:34,476] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:44:34,495] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:44:34,524] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:44:34,539] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:44:34,539] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:44:34,544] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:44:34,544] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:44:34,544] INFO Kafka startTimeMs: 1651657474540 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:44:34,548] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-04 11:44:34,664] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker fedora:9093 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:34,710] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9093 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:44:34,790] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,823] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-1/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,825] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-04 11:44:34,826] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,833] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,837] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-1/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,837] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-04 11:44:34,837] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,846] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,848] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-1/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,848] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-04 11:44:34,848] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,855] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,858] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-1/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,858] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-04 11:44:34,858] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,865] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,867] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-1/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,867] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-04 11:44:34,868] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,875] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,877] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-1/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,877] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-04 11:44:34,877] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,882] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,884] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-1/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,885] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-04 11:44:34,885] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,894] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,896] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-1/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,896] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-04 11:44:34,896] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,902] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,904] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-1/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,905] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-04 11:44:34,905] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,911] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,913] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-1/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,913] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-04 11:44:34,914] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,922] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,924] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-1/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,924] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-04 11:44:34,924] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,930] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,932] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-1/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,933] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-04 11:44:34,933] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,941] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,943] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-1/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,943] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,943] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,951] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,953] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-1/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,953] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-04 11:44:34,954] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,963] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,965] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-1/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,965] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-04 11:44:34,965] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,974] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,977] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-1/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,977] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-04 11:44:34,977] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,986] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,989] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-1/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,990] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-04 11:44:34,990] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:34,996] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:34,998] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-1/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:34,999] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-04 11:44:34,999] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:35,008] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:35,009] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-1/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:35,010] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-04 11:44:35,010] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:35,015] INFO [LogLoader partition=output-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:35,018] INFO Created log for partition output-0 in /tmp/kafka-logs-1/output-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:44:35,018] INFO [Partition output-0 broker=1] No checkpointed highwatermark is found for partition output-0 (kafka.cluster.Partition)
[2022-05-04 11:44:35,018] INFO [Partition output-0 broker=1] Log loaded for partition output-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:35,025] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:35,027] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-1/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:35,027] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-04 11:44:35,028] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:35,034] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:35,035] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-1/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:35,036] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-04 11:44:35,036] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:35,044] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:35,045] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-1/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:35,046] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-04 11:44:35,046] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:35,053] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:35,056] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-1/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:35,056] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-04 11:44:35,056] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:35,062] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:35,063] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-1/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:35,064] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-04 11:44:35,064] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:35,069] INFO [LogLoader partition=provatop-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:35,071] INFO Created log for partition provatop-0 in /tmp/kafka-logs-1/provatop-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:44:35,072] INFO [Partition provatop-0 broker=1] No checkpointed highwatermark is found for partition provatop-0 (kafka.cluster.Partition)
[2022-05-04 11:44:35,072] INFO [Partition provatop-0 broker=1] Log loaded for partition provatop-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:35,079] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:44:35,081] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-1/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:44:35,081] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-04 11:44:35,081] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:44:35,123] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, provatop-0, __consumer_offsets-46, output-0, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-48, __consumer_offsets-12, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-8, __consumer_offsets-4, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:44:35,165] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,166] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,169] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,169] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,169] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,169] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,170] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,170] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,170] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,170] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,170] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,170] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,170] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,170] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,170] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,171] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,171] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,171] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,171] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,171] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,171] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,171] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,171] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,171] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,171] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,171] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,171] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,171] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,172] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,172] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,172] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,172] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,172] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,172] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,172] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,172] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,172] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,173] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,173] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,173] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,173] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,173] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,173] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,173] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,173] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,173] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,173] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,173] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,173] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:35,174] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,180] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 10 milliseconds for epoch 9, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,181] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 12 milliseconds for epoch 9, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,187] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 16 milliseconds for epoch 9, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 18 milliseconds for epoch 9, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,189] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 19 milliseconds for epoch 9, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,189] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 19 milliseconds for epoch 9, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,190] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 20 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,190] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 19 milliseconds for epoch 9, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,191] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 20 milliseconds for epoch 9, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,191] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 20 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,191] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 20 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,192] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 21 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,192] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 21 milliseconds for epoch 9, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,192] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 20 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,192] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 20 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,193] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 21 milliseconds for epoch 9, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,193] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 21 milliseconds for epoch 9, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,193] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 21 milliseconds for epoch 9, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,194] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 21 milliseconds for epoch 9, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,194] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 21 milliseconds for epoch 9, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,194] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 21 milliseconds for epoch 9, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,195] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 22 milliseconds for epoch 9, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,195] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 22 milliseconds for epoch 9, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,196] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 22 milliseconds for epoch 9, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:35,196] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 22 milliseconds for epoch 9, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:44:54,518] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-a4f595a8-1b92-4854-8d16-a58b285c93d6 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:54,574] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member rdkafka-a4f595a8-1b92-4854-8d16-a58b285c93d6 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:54,602] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 1 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:44:54,644] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-a4f595a8-1b92-4854-8d16-a58b285c93d6 for group gruppo for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:45:54,414] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: Removing member rdkafka-a4f595a8-1b92-4854-8d16-a58b285c93d6 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:45:54,417] INFO [GroupCoordinator 2]: Group gruppo with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:45:54,421] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-a4f595a8-1b92-4854-8d16-a58b285c93d6, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.1.114, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:13,393] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:46:13,394] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-04 11:46:13,396] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 11:46:13,432] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 17ms (kafka.server.KafkaServer)
[2022-05-04 11:46:13,438] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:46:13,439] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:46:13,439] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:46:13,440] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:46:13,453] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:46:13,456] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:46:13,460] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:46:13,464] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,558] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,558] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,559] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 11:46:13,561] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,620] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,620] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,626] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:46:13,627] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 11:46:13,627] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:46:13,628] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:46:13,628] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:46:13,629] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:46:13,630] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:13,630] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,660] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,661] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,665] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,833] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,833] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,835] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:13,837] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 11:46:13,839] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:46:13,839] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:46:13,839] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:46:13,840] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:46:13,843] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:46:13,843] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:46:13,844] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:46:13,844] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,909] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,909] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:13,910] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:14,108] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:14,108] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:14,109] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:14,308] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:14,308] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:14,309] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:14,508] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:14,511] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:14,513] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 11:46:14,514] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:14,514] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:14,514] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:14,519] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:46:14,520] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:14,520] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:14,521] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:14,521] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:46:14,524] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 11:46:14,548] INFO [ProducerStateManager partition=output-0] Wrote producer snapshot at offset 591342 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:46:14,559] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 11:46:14,564] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:46:14,564] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:46:14,564] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:46:14,566] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:46:14,674] INFO EventThread shut down for session: 0x10000f5b64d0001 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:46:14,675] INFO Session: 0x10000f5b64d0001 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:14,676] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:46:14,677] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:15,061] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:46:15,063] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-04 11:46:15,064] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 11:46:15,081] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 4ms (kafka.server.KafkaServer)
[2022-05-04 11:46:15,092] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:46:15,092] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:46:15,093] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:46:15,094] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:46:15,109] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:46:15,110] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:46:15,112] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:46:15,115] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,185] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,185] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,186] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 11:46:15,188] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,207] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:15,207] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:15,208] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:15,211] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:15,211] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:15,211] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:15,214] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:15,214] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:15,214] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:15,344] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,344] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,347] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:46:15,349] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 11:46:15,349] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:46:15,349] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:46:15,349] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:46:15,350] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:46:15,351] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:15,351] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,477] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,477] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,478] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,504] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,504] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,506] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:15,508] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 11:46:15,509] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:46:15,510] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:46:15,510] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:46:15,511] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:46:15,512] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:46:15,513] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:46:15,513] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:46:15,513] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,590] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,590] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,591] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,786] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,786] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,787] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,862] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,862] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,862] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,991] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,991] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:15,995] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 11:46:15,996] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:15,996] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:15,996] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:16,002] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:46:16,003] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:16,003] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:16,003] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:16,004] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:46:16,004] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 11:46:16,027] INFO [ProducerStateManager partition=__consumer_offsets-37] Wrote producer snapshot at offset 14 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:46:16,033] INFO [ProducerStateManager partition=input-0] Wrote producer snapshot at offset 13660108 with 0 producer ids in 0 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:46:16,040] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 11:46:16,050] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:46:16,051] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:46:16,051] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:46:16,052] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:46:16,055] WARN An exception was thrown while closing send thread for session 0x10000f5b64d0000. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x10000f5b64d0000, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 11:46:16,158] INFO Session: 0x10000f5b64d0000 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:16,158] INFO EventThread shut down for session: 0x10000f5b64d0000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:46:16,161] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:46:16,162] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:16,214] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:16,214] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:16,215] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 11:46:16,245] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 11:46:16,247] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:46:16,247] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:46:16,247] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:46:16,250] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 11:46:16,251] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:46:16,252] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-04 11:46:16,884] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:16,884] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:16,885] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:17,884] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:17,884] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:17,885] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:18,885] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:18,885] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:18,885] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:19,885] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:19,885] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:19,888] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 11:46:19,956] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 11:46:19,957] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:46:19,957] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:46:19,957] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:46:19,960] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 11:46:19,961] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:46:19,961] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-04 11:46:26,715] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:46:26,717] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:46:26,725] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:46:26,725] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:46:26,725] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:46:26,726] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:46:26,729] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:46:26,729] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:46:26,729] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:46:26,729] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-04 11:46:26,738] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-04 11:46:26,765] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:46:26,765] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:46:26,766] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:46:26,766] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:46:26,766] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:46:26,767] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:46:26,767] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-04 11:46:26,791] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@ca263c2 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-04 11:46:26,797] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:46:26,817] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,819] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,819] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,820] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,820] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,820] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,820] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,820] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,820] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,820] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,824] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,824] INFO Server environment:host.name=fedora (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,824] INFO Server environment:java.version=16.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,824] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,825] INFO Server environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,825] INFO Server environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,825] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,825] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,825] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,826] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,826] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,826] INFO Server environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,826] INFO Server environment:user.name=della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,826] INFO Server environment:user.home=/home/della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,826] INFO Server environment:user.dir=/home/della/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,826] INFO Server environment:os.memory.free=495MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,826] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,826] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,827] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,827] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,827] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,827] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,827] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,827] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,828] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,830] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-04 11:46:26,833] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,834] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,838] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:46:26,839] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:46:26,841] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:46:26,841] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:46:26,841] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:46:26,841] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:46:26,842] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:46:26,842] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:46:26,845] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,845] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,845] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:26,861] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:46:26,863] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:46:26,867] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:46:26,874] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:46:26,895] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:46:26,895] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:46:26,896] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:46:26,897] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:46:26,906] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-04 11:46:26,908] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.432 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-05-04 11:46:26,925] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x432, and digest value as 321570616548 (org.apache.zookeeper.server.DataTree)
[2022-05-04 11:46:26,976] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-04 11:46:26,984] INFO 117 txns loaded in 40 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:46:26,984] INFO Snapshot loaded in 88 ms, highest zxid is 0x4a7, digest is 302531880627 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:46:26,985] INFO Snapshotting: 0x4a7 to /tmp/zookeeper/version-2/snapshot.4a7 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:46:26,991] INFO Snapshot taken in 6 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:46:27,009] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-04 11:46:27,009] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-04 11:46:27,044] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-04 11:46:38,273] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:46:38,651] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:46:38,816] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:46:38,824] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:46:38,826] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:46:38,853] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:46:38,862] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,862] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,862] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,862] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,862] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,862] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,863] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,863] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,863] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,863] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,863] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,863] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,863] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,863] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,864] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,864] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,864] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,864] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,867] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7d94beb9 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:38,878] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:46:38,888] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:46:38,897] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:46:38,904] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:46:38,905] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:46:38,911] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:40478, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:46:38,926] INFO Creating new log file: log.4a8 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-04 11:46:38,941] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10000f7ca0f0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:46:38,948] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:46:39,092] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:46:39,350] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:46:39,361] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:46:39,367] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:46:39,453] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:46:39,495] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:46:39,548] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:46:39,562] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:39,564] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:39,567] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:39,569] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:39,597] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:46:39,661] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 11:46:39,672] INFO Attempting recovery for all logs in /tmp/kafka-logs-1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:46:39,689] INFO Loaded 0 logs in 28ms. (kafka.log.LogManager)
[2022-05-04 11:46:39,692] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:46:39,700] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:46:40,006] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:46:40,188] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:40,189] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:46:40,197] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:46:40,198] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:46:40,230] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:46:40,239] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,239] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,240] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,240] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,240] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,240] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,240] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,241] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,241] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,241] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,241] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,241] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,241] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,241] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,241] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,241] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,241] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,242] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,246] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:46:40,260] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:46:40,270] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:46:40,277] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:46:40,284] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:46:40,285] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:46:40,292] INFO Socket connection established, initiating session, client: /127.0.0.1:42610, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:46:40,302] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10000f7ca0f0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:46:40,310] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:46:40,458] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:46:40,731] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:46:40,737] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-04 11:46:40,776] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:46:40,792] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:46:40,802] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:46:40,830] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:46:40,849] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:40,885] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:40,886] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:40,889] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:40,894] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:40,897] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:46:40,915] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:46:40,939] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:46:40,988] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:40,990] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:40,992] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:40,993] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:46:41,025] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:46:41,025] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:46:41,072] INFO Stat of the created znode at /brokers/ids/1 is: 1222,1222,1651657601062,1651657601062,1,0,0,72058658284830720,196,0,1222
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:46:41,074] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://fedora:9092, czxid (broker epoch): 1222 (kafka.zk.KafkaZkClient)
[2022-05-04 11:46:41,107] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 11:46:41,116] INFO Attempting recovery for all logs in /tmp/kafka-logs-2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:46:41,131] INFO Loaded 0 logs in 23ms. (kafka.log.LogManager)
[2022-05-04 11:46:41,132] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:46:41,139] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:46:41,195] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:41,206] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:41,210] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:41,250] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:41,283] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:41,321] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:46:41,340] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:46:41,351] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:46:41,397] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:41,482] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:46:41,585] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:46:41,593] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:46:41,594] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:46:41,609] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:46:41,609] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:46:41,609] INFO Kafka startTimeMs: 1651657601594 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:46:41,611] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-04 11:46:41,759] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:41,836] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:41,844] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:42,365] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,409] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-1/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,423] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-04 11:46:42,449] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,524] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,533] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-1/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,533] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-04 11:46:42,533] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,548] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,565] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-1/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,565] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-04 11:46:42,566] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,574] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,576] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-1/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,577] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-04 11:46:42,577] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,592] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,594] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-1/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,594] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-04 11:46:42,594] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,609] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,611] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-1/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,611] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-04 11:46:42,612] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,625] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:46:42,632] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,637] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-1/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,637] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-04 11:46:42,633] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-04 11:46:42,638] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,656] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,662] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-1/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,662] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-04 11:46:42,662] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,675] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,677] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-1/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,677] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-04 11:46:42,677] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,687] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,690] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-1/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,691] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-04 11:46:42,691] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,702] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,708] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-1/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,708] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-04 11:46:42,708] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,717] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,722] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-1/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,722] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-04 11:46:42,723] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,729] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,733] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-1/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,733] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,733] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,744] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,747] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-1/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,748] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-04 11:46:42,748] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,759] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,763] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-1/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,764] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-04 11:46:42,764] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,781] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,779] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:46:42,786] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-1/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,787] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-04 11:46:42,787] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,798] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,805] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-1/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,806] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-04 11:46:42,806] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,816] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,819] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-1/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,819] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-04 11:46:42,819] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,821] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:42,830] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,835] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-1/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,835] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-04 11:46:42,835] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,844] INFO [LogLoader partition=output-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,850] INFO Created log for partition output-0 in /tmp/kafka-logs-1/output-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:46:42,850] INFO [Partition output-0 broker=1] No checkpointed highwatermark is found for partition output-0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,850] INFO [Partition output-0 broker=1] Log loaded for partition output-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,860] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,864] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-1/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,865] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-04 11:46:42,866] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,868] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:42,874] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:42,876] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:42,880] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,881] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:42,883] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-1/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,884] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-04 11:46:42,884] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,894] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,895] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-1/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,898] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-04 11:46:42,898] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,913] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,917] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-1/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,917] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-04 11:46:42,917] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,929] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:46:42,936] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,938] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-1/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,938] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-04 11:46:42,938] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,950] INFO [LogLoader partition=provatop-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,955] INFO Created log for partition provatop-0 in /tmp/kafka-logs-1/provatop-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:46:42,955] INFO [Partition provatop-0 broker=1] No checkpointed highwatermark is found for partition provatop-0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,955] INFO [Partition provatop-0 broker=1] Log loaded for partition provatop-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:42,963] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:42,966] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-1/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:42,966] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-04 11:46:42,966] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:43,041] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, provatop-0, __consumer_offsets-46, output-0, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-48, __consumer_offsets-12, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-8, __consumer_offsets-4, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:46:43,057] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:46:43,094] INFO Stat of the created znode at /brokers/ids/2 is: 1278,1278,1651657603076,1651657603076,1,0,0,72058658284830721,196,0,1278
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:46:43,096] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://fedora:9093, czxid (broker epoch): 1278 (kafka.zk.KafkaZkClient)
[2022-05-04 11:46:43,132] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,133] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,138] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,138] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,139] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,139] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,139] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,139] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,139] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,139] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,139] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,139] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,139] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,139] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,140] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,140] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,140] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,140] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,140] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,140] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,140] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,140] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,141] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,141] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,141] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,141] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,141] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,141] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,141] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,141] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,141] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,141] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,142] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,142] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,142] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,142] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,150] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,150] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,150] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,151] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,151] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,151] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,151] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,151] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,151] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,151] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,151] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,151] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,151] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 11 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,151] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 11 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,161] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 19 milliseconds for epoch 11, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,163] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 25 milliseconds for epoch 11, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,164] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 25 milliseconds for epoch 11, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,175] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 36 milliseconds for epoch 11, of which 35 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,176] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 37 milliseconds for epoch 11, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,176] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 37 milliseconds for epoch 11, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,177] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 38 milliseconds for epoch 11, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,178] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 38 milliseconds for epoch 11, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,184] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 44 milliseconds for epoch 11, of which 44 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,185] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 45 milliseconds for epoch 11, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,186] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 45 milliseconds for epoch 11, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 47 milliseconds for epoch 11, of which 47 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,193] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 51 milliseconds for epoch 11, of which 51 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,193] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 52 milliseconds for epoch 11, of which 52 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,196] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 55 milliseconds for epoch 11, of which 55 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,217] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 76 milliseconds for epoch 11, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,218] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 76 milliseconds for epoch 11, of which 76 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,223] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 73 milliseconds for epoch 11, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,224] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 74 milliseconds for epoch 11, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,225] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 74 milliseconds for epoch 11, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,231] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 80 milliseconds for epoch 11, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,233] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 82 milliseconds for epoch 11, of which 82 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,234] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 83 milliseconds for epoch 11, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,235] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 84 milliseconds for epoch 11, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,239] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 87 milliseconds for epoch 11, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:43,284] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:43,303] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:43,317] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:43,341] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,368] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:43,401] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:46:43,408] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:46:43,409] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:46:43,445] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:46:43,473] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:46:43,510] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:46:43,528] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:46:43,529] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:46:43,538] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:46:43,539] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:46:43,539] INFO Kafka startTimeMs: 1651657603529 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:46:43,541] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-04 11:46:43,633] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:43,715] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:46:43,873] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:43,907] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-2/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:43,912] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-04 11:46:43,913] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:43,926] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:43,929] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-2/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:43,930] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-04 11:46:43,930] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:43,940] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:43,946] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-2/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:43,946] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-04 11:46:43,946] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:43,956] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:43,957] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-2/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:43,958] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-04 11:46:43,958] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:43,967] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:43,971] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-2/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:43,972] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-04 11:46:43,972] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:43,978] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:43,980] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-2/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:43,980] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-04 11:46:43,980] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:43,989] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:43,991] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-2/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:43,991] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-04 11:46:43,991] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:43,997] INFO [LogLoader partition=input-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,000] INFO Created log for partition input-0 in /tmp/kafka-logs-2/input-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:46:44,000] INFO [Partition input-0 broker=2] No checkpointed highwatermark is found for partition input-0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,000] INFO [Partition input-0 broker=2] Log loaded for partition input-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,009] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,011] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-2/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,011] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-04 11:46:44,011] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,019] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,022] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-2/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,023] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-04 11:46:44,023] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,030] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,031] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-2/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,031] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-04 11:46:44,032] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,045] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,047] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-2/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,048] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-04 11:46:44,049] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,056] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,058] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-2/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,058] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-04 11:46:44,058] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,063] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,064] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-2/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,064] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-04 11:46:44,064] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,073] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,075] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-2/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,075] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-04 11:46:44,075] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,083] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,086] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-2/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,088] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-04 11:46:44,089] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,094] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,095] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-2/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,096] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-04 11:46:44,096] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,102] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,106] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-2/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,106] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-04 11:46:44,106] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,112] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,114] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-2/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,114] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-04 11:46:44,115] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,129] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,131] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-2/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,134] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-04 11:46:44,134] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,147] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,151] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-2/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,152] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-04 11:46:44,153] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,165] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,168] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-2/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,168] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-04 11:46:44,168] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,175] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,176] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-2/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,176] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-04 11:46:44,177] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,184] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,186] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-2/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,187] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-04 11:46:44,188] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,194] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,196] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-2/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,196] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-04 11:46:44,196] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,202] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:46:44,204] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-2/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:46:44,204] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-04 11:46:44,204] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:46:44,245] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, input-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:46:44,293] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 3 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,294] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,297] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,297] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,297] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,297] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,297] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,299] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,299] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,299] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,299] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 33 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,299] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,299] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,299] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,300] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,300] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,300] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,300] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,300] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 45 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,300] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,300] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,300] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,300] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,300] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,300] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,300] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,300] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,300] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,300] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 39 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,300] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,301] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 9 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,301] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,301] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 27 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,301] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,301] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,301] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,301] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,301] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,301] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 21 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,301] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,301] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,301] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,301] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,301] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,302] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,302] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,302] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,302] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,302] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:46:44,302] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,322] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 23 milliseconds for epoch 18, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,323] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 26 milliseconds for epoch 18, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,323] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 26 milliseconds for epoch 18, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,324] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 25 milliseconds for epoch 18, of which 24 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,324] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 25 milliseconds for epoch 18, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,324] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 25 milliseconds for epoch 18, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,325] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 25 milliseconds for epoch 18, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,325] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 25 milliseconds for epoch 18, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,326] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 25 milliseconds for epoch 18, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,326] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 26 milliseconds for epoch 18, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,326] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 26 milliseconds for epoch 18, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,327] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 27 milliseconds for epoch 18, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,327] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 27 milliseconds for epoch 18, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,328] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 28 milliseconds for epoch 18, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,328] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 27 milliseconds for epoch 18, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,328] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 27 milliseconds for epoch 18, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,329] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 28 milliseconds for epoch 18, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,329] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 28 milliseconds for epoch 18, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,330] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 28 milliseconds for epoch 18, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,330] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 29 milliseconds for epoch 18, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,330] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 29 milliseconds for epoch 18, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,331] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 29 milliseconds for epoch 18, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,331] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 29 milliseconds for epoch 18, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,332] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 30 milliseconds for epoch 18, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:46:44,333] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 31 milliseconds for epoch 18, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:47:27,751] INFO [LocalLog partition=input-0, dir=/tmp/kafka-logs-2] Rolled new log segment at offset 34798377 in 5 ms. (kafka.log.LocalLog)
[2022-05-04 11:47:27,755] INFO [ProducerStateManager partition=input-0] Wrote producer snapshot at offset 34798377 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:47:55,736] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-04a0fdc9-9c76-449d-b702-6c6c7d64d709 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:47:55,759] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member rdkafka-04a0fdc9-9c76-449d-b702-6c6c7d64d709 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:47:55,777] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 1 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:47:55,804] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-04a0fdc9-9c76-449d-b702-6c6c7d64d709 for group gruppo for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:48:55,657] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: Removing member rdkafka-04a0fdc9-9c76-449d-b702-6c6c7d64d709 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:48:55,659] INFO [GroupCoordinator 2]: Group gruppo with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:48:55,661] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-04a0fdc9-9c76-449d-b702-6c6c7d64d709, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.122.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:49:02,301] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-aa841d4a-504e-4db9-b65a-30a9cf622660 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:49:02,304] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 2 (__consumer_offsets-37) (reason: Adding new member rdkafka-aa841d4a-504e-4db9-b65a-30a9cf622660 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:49:02,305] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 3 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:49:02,307] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-aa841d4a-504e-4db9-b65a-30a9cf622660 for group gruppo for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:50:02,303] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 3 (__consumer_offsets-37) (reason: Removing member rdkafka-aa841d4a-504e-4db9-b65a-30a9cf622660 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:50:02,303] INFO [GroupCoordinator 2]: Group gruppo with generation 4 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:50:02,304] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-aa841d4a-504e-4db9-b65a-30a9cf622660, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.1.114, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:50:17,444] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-21085480-c0c8-4fa9-a96b-2e37689c6ff5 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:50:17,445] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 4 (__consumer_offsets-37) (reason: Adding new member rdkafka-21085480-c0c8-4fa9-a96b-2e37689c6ff5 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:50:17,446] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 5 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:50:17,448] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-21085480-c0c8-4fa9-a96b-2e37689c6ff5 for group gruppo for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:50:44,085] INFO [LocalLog partition=input-0, dir=/tmp/kafka-logs-2] Rolled new log segment at offset 69594111 in 26 ms. (kafka.log.LocalLog)
[2022-05-04 11:50:44,087] INFO [ProducerStateManager partition=input-0] Wrote producer snapshot at offset 69594111 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:51:17,445] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 5 (__consumer_offsets-37) (reason: Removing member rdkafka-21085480-c0c8-4fa9-a96b-2e37689c6ff5 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:51:17,446] INFO [GroupCoordinator 2]: Group gruppo with generation 6 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:51:17,446] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-21085480-c0c8-4fa9-a96b-2e37689c6ff5, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.122.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:51:28,355] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-f892f922-6453-444b-97d3-402599cc5b80 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:51:28,360] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 6 (__consumer_offsets-37) (reason: Adding new member rdkafka-f892f922-6453-444b-97d3-402599cc5b80 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:51:28,361] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 7 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:51:28,370] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-f892f922-6453-444b-97d3-402599cc5b80 for group gruppo for generation 7. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:51:49,317] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:51:49,327] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-04 11:51:49,328] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 11:51:49,366] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 17ms (kafka.server.KafkaServer)
[2022-05-04 11:51:49,386] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:51:49,388] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:51:49,389] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:51:49,389] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:51:49,397] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:51:49,399] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:51:49,401] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:51:49,405] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,418] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,418] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,420] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 11:51:49,421] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,618] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,618] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,621] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:51:49,622] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 11:51:49,622] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:51:49,622] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:51:49,622] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:51:49,623] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:51:49,623] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:51:49,624] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,716] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,716] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,717] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,916] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,916] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,918] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:51:49,921] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 11:51:49,921] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:51:49,922] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:51:49,922] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:51:49,923] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:51:49,925] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:51:49,925] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:51:49,926] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:51:49,926] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,967] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,967] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:49,967] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:50,072] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:51:50,073] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-04 11:51:50,075] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 11:51:50,092] INFO [KafkaServer id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-04 11:51:50,093] WARN [KafkaServer id=2] Connection to node 1 (fedora/192.168.1.114:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-04 11:51:50,094] WARN [KafkaServer id=2] Error during controlled shutdown, possibly because leader movement took longer than the configured controller.socket.timeout.ms and/or request.timeout.ms: Connection to fedora:9092 (id: 1 rack: null) failed. (kafka.server.KafkaServer)
[2022-05-04 11:51:50,167] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:50,167] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:50,168] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:50,253] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:50,253] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:50,253] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:50,367] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:50,367] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:50,371] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 11:51:50,371] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:51:50,372] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:51:50,372] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:51:50,376] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:51:50,377] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:51:50,377] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:51:50,378] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:51:50,378] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:51:50,379] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 11:51:50,416] INFO [ProducerStateManager partition=output-0] Wrote producer snapshot at offset 693728 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:51:50,427] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 11:51:50,440] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:51:50,440] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:51:50,440] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:51:50,441] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:51:50,547] INFO EventThread shut down for session: 0x10000f7ca0f0000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:51:50,548] INFO Session: 0x10000f7ca0f0000 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:51:50,553] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:51:50,554] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:50,624] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:50,626] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:50,626] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:51,623] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:51,623] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:51,624] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:51,655] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:51,655] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:51,655] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:51,661] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:51,661] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:51,664] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 11:51:51,704] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 11:51:51,705] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:51:51,705] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:51:51,705] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:51:51,708] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 11:51:51,709] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:51:51,710] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-04 11:51:55,095] INFO [KafkaServer id=2] Retrying controlled shutdown (2 retries remaining) (kafka.server.KafkaServer)
[2022-05-04 11:51:55,095] INFO [KafkaServer id=2] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 11:51:55,107] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 11ms (kafka.server.KafkaServer)
[2022-05-04 11:51:55,116] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:51:55,117] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:51:55,117] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:51:55,118] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:51:55,129] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 11:51:55,130] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:51:55,134] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 11:51:55,138] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,171] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,171] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,172] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 11:51:55,173] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,371] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,371] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,377] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:51:55,379] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 11:51:55,379] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:51:55,379] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:51:55,379] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:51:55,381] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:51:55,383] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:51:55,384] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,481] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,481] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,482] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,624] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,624] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,626] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:51:55,628] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 11:51:55,629] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:51:55,629] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:51:55,629] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:51:55,630] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:51:55,633] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:51:55,634] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:51:55,634] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:51:55,634] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,774] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,774] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,775] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,973] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,973] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:55,974] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:56,171] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:56,172] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:56,173] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:56,174] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:56,174] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:51:56,177] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 11:51:56,178] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:51:56,179] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:51:56,179] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:51:56,185] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:51:56,186] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:51:56,187] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:51:56,187] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:51:56,188] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 11:51:56,190] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 11:51:56,215] INFO [ProducerStateManager partition=__consumer_offsets-37] Wrote producer snapshot at offset 22 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:51:56,218] INFO [ProducerStateManager partition=input-0] Wrote producer snapshot at offset 94849001 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:51:56,224] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 11:51:56,233] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:51:56,234] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:51:56,234] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:51:56,235] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:51:56,339] INFO Session: 0x10000f7ca0f0001 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:51:56,339] INFO EventThread shut down for session: 0x10000f7ca0f0001 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:51:56,341] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:51:56,342] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:57,028] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:57,028] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:57,028] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:57,052] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:57,052] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:57,052] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:58,046] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:58,046] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:58,046] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:59,044] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:59,044] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:51:59,047] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 11:51:59,112] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 11:51:59,113] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:51:59,113] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:51:59,113] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 11:51:59,117] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 11:51:59,118] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:51:59,119] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-04 11:53:02,112] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:53:02,114] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:53:02,121] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:53:02,121] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:53:02,121] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:53:02,122] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:53:02,125] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:53:02,126] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:53:02,126] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:53:02,126] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-04 11:53:02,133] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-04 11:53:02,157] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:53:02,157] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:53:02,158] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:53:02,158] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:53:02,158] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:53:02,158] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:53:02,158] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-04 11:53:02,183] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@ca263c2 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-04 11:53:02,189] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:53:02,210] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,210] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,210] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,210] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,210] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,210] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,210] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,211] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,211] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,211] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,213] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,213] INFO Server environment:host.name=fedora (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,213] INFO Server environment:java.version=16.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,213] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,215] INFO Server environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,216] INFO Server environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,217] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,217] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,217] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,217] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,217] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,217] INFO Server environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,217] INFO Server environment:user.name=della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,217] INFO Server environment:user.home=/home/della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,217] INFO Server environment:user.dir=/home/della/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,217] INFO Server environment:os.memory.free=495MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,218] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,218] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,218] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,218] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,218] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,218] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,218] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,219] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,219] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,221] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-04 11:53:02,223] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,223] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,226] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:53:02,227] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:53:02,229] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:53:02,230] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:53:02,230] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:53:02,231] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:53:02,231] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:53:02,231] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:53:02,236] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,236] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,237] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,254] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:53:02,256] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:53:02,259] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:53:02,263] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:53:02,286] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:53:02,287] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:53:02,288] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:53:02,288] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:53:02,295] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-04 11:53:02,297] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.4a7 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-05-04 11:53:02,316] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x4a7, and digest value as 302531880627 (org.apache.zookeeper.server.DataTree)
[2022-05-04 11:53:02,376] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-04 11:53:02,386] INFO 144 txns loaded in 54 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:53:02,387] INFO Snapshot loaded in 98 ms, highest zxid is 0x537, digest is 304119538351 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:53:02,387] INFO Snapshotting: 0x537 to /tmp/zookeeper/version-2/snapshot.537 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:53:02,394] INFO Snapshot taken in 7 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:53:02,411] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-04 11:53:02,411] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-04 11:53:02,461] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-04 11:53:15,178] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:53:15,619] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:53:15,802] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:53:15,812] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:53:15,813] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:53:15,860] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:53:15,877] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,877] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,877] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,877] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,877] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,877] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,878] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,878] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,878] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,878] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,878] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,878] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,878] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,879] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,879] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,879] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,879] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,879] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,884] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:15,900] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:53:15,916] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:53:15,922] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:53:15,938] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:53:15,939] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:53:15,946] INFO Socket connection established, initiating session, client: /127.0.0.1:42612, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:53:15,962] INFO Creating new log file: log.538 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-04 11:53:15,977] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10000fdd29b0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:53:15,985] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:53:16,158] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:53:16,470] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:53:16,482] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:53:16,491] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:53:16,590] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:53:16,633] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:53:16,748] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:53:16,752] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:53:16,754] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:53:16,756] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:53:16,783] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:53:16,783] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:53:16,851] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 11:53:16,870] INFO Attempting recovery for all logs in /tmp/kafka-logs-1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:53:16,886] INFO Loaded 0 logs in 34ms. (kafka.log.LogManager)
[2022-05-04 11:53:16,888] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:53:16,895] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:53:17,304] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:53:17,532] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:53:17,542] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:53:17,553] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:53:17,555] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:53:17,588] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:53:17,607] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,607] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,610] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,610] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,611] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,611] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,611] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,611] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,611] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,612] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,612] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,612] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,612] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,612] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,612] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,612] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,612] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,612] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,617] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7d94beb9 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:53:17,631] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:53:17,642] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:53:17,649] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:53:17,670] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:53:17,671] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:53:17,678] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:40480, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:53:17,690] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10000fdd29b0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:53:17,701] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:53:17,858] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:53:18,123] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:53:18,131] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-04 11:53:18,154] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:53:18,190] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:53:18,203] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:53:18,216] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:53:18,247] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:53:18,272] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:18,276] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:18,276] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:18,279] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:18,292] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:53:18,311] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:53:18,320] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:53:18,384] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:53:18,386] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:53:18,387] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:53:18,389] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:53:18,400] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:53:18,418] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:53:18,438] INFO Stat of the created znode at /brokers/ids/1 is: 1366,1366,1651657998425,1651657998425,1,0,0,72058684198027264,196,0,1366
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:53:18,440] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://fedora:9092, czxid (broker epoch): 1366 (kafka.zk.KafkaZkClient)
[2022-05-04 11:53:18,474] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 11:53:18,483] INFO Attempting recovery for all logs in /tmp/kafka-logs-2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:53:18,496] INFO Loaded 0 logs in 22ms. (kafka.log.LogManager)
[2022-05-04 11:53:18,498] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:53:18,504] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:53:18,575] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:18,617] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:18,629] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:18,671] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:18,712] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:18,766] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:53:18,787] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:53:18,792] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:53:18,854] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:18,933] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:53:19,062] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:53:19,088] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:53:19,089] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:53:19,118] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:53:19,119] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:53:19,119] INFO Kafka startTimeMs: 1651657999089 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:53:19,134] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-04 11:53:19,250] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:53:19,373] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:53:19,392] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:53:19,956] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:19,984] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-1/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:19,988] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-04 11:53:19,990] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,010] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,019] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-1/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,019] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-04 11:53:20,019] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,078] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,086] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-1/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,086] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-04 11:53:20,086] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,123] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,145] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:53:20,146] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-1/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,147] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-04 11:53:20,147] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,159] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-04 11:53:20,193] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,198] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-1/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,198] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-04 11:53:20,199] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,211] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,220] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-1/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,224] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-04 11:53:20,225] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,263] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:53:20,255] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,266] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-1/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,269] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-04 11:53:20,269] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,297] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,313] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-1/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,317] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-04 11:53:20,323] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,329] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:53:20,339] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,350] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-1/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,354] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-04 11:53:20,354] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,382] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,388] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-1/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,388] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-04 11:53:20,388] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,390] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:20,395] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:20,406] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,406] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:20,408] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-1/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,408] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-04 11:53:20,408] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,434] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,436] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:20,439] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-1/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,442] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-04 11:53:20,442] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,460] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,465] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-1/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,467] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,468] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,478] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,484] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-1/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,484] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-04 11:53:20,484] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,487] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:53:20,503] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,506] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-1/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,506] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-04 11:53:20,506] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,517] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,520] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-1/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,520] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-04 11:53:20,520] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,527] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,532] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-1/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,533] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-04 11:53:20,533] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,545] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,550] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-1/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,550] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-04 11:53:20,550] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,558] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,564] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-1/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,564] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-04 11:53:20,565] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,571] INFO [LogLoader partition=output-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,573] INFO Created log for partition output-0 in /tmp/kafka-logs-1/output-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:53:20,574] INFO [Partition output-0 broker=1] No checkpointed highwatermark is found for partition output-0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,574] INFO [Partition output-0 broker=1] Log loaded for partition output-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,582] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,585] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-1/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,585] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-04 11:53:20,585] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,593] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,596] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-1/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,596] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-04 11:53:20,596] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,607] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,610] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-1/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,610] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-04 11:53:20,610] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,623] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,642] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:53:20,642] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-1/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,644] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-04 11:53:20,644] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,654] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,661] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-1/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,661] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-04 11:53:20,661] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,695] INFO Stat of the created znode at /brokers/ids/2 is: 1422,1422,1651658000686,1651658000686,1,0,0,72058684198027265,196,0,1422
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:53:20,698] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://fedora:9093, czxid (broker epoch): 1422 (kafka.zk.KafkaZkClient)
[2022-05-04 11:53:20,709] INFO [LogLoader partition=provatop-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,737] INFO Created log for partition provatop-0 in /tmp/kafka-logs-1/provatop-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:53:20,747] INFO [Partition provatop-0 broker=1] No checkpointed highwatermark is found for partition provatop-0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,747] INFO [Partition provatop-0 broker=1] Log loaded for partition provatop-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,767] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:20,769] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-1/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:20,770] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-04 11:53:20,770] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:20,871] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:20,907] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:20,916] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, provatop-0, __consumer_offsets-46, output-0, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-48, __consumer_offsets-12, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-8, __consumer_offsets-4, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:53:20,923] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:20,956] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,005] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,043] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,055] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,068] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:53:21,070] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,070] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,072] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,072] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,073] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,073] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,073] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,073] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,073] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,073] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,073] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,073] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,073] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,074] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,074] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,083] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,083] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,084] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,084] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,084] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,084] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,084] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,084] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,084] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,084] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,084] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,084] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,084] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,084] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,084] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,084] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,085] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,085] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,085] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,085] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,085] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,085] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,085] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,085] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,085] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,085] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,085] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,085] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,085] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,085] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,078] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 12 milliseconds for epoch 13, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,086] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 16 milliseconds for epoch 13, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,086] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 14 milliseconds for epoch 13, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,088] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 15 milliseconds for epoch 13, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,089] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 15 milliseconds for epoch 13, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,089] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 16 milliseconds for epoch 13, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,089] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 16 milliseconds for epoch 13, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,089] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:53:21,093] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 19 milliseconds for epoch 13, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,090] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:53:21,099] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 25 milliseconds for epoch 13, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,100] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 17 milliseconds for epoch 13, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,100] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 17 milliseconds for epoch 13, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,101] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 17 milliseconds for epoch 13, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,101] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 17 milliseconds for epoch 13, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,102] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 18 milliseconds for epoch 13, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,102] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 18 milliseconds for epoch 13, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,103] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 19 milliseconds for epoch 13, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,103] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 19 milliseconds for epoch 13, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,103] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 18 milliseconds for epoch 13, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,104] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 19 milliseconds for epoch 13, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,104] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 19 milliseconds for epoch 13, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,105] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 20 milliseconds for epoch 13, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,105] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 20 milliseconds for epoch 13, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,105] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 20 milliseconds for epoch 13, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,114] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 29 milliseconds for epoch 13, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,115] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 30 milliseconds for epoch 13, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,153] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:53:21,185] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:53:21,227] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:53:21,249] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:53:21,249] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:53:21,255] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:53:21,255] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:53:21,255] INFO Kafka startTimeMs: 1651658001250 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:53:21,266] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-04 11:53:21,350] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:53:21,411] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker fedora:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:53:21,556] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,595] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-2/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,599] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-04 11:53:21,602] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,609] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,616] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-2/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,617] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-04 11:53:21,617] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,626] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,628] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-2/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,628] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-04 11:53:21,628] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,638] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,641] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-2/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,641] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-04 11:53:21,641] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,652] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,655] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-2/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,655] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-04 11:53:21,655] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,661] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,663] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-2/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,663] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-04 11:53:21,663] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,670] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,672] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-2/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,672] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-04 11:53:21,672] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,678] INFO [LogLoader partition=input-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,680] INFO Created log for partition input-0 in /tmp/kafka-logs-2/input-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:53:21,680] INFO [Partition input-0 broker=2] No checkpointed highwatermark is found for partition input-0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,680] INFO [Partition input-0 broker=2] Log loaded for partition input-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,690] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,692] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-2/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,692] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-04 11:53:21,692] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,699] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,701] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-2/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,701] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-04 11:53:21,701] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,708] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,710] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-2/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,710] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-04 11:53:21,710] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,718] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,720] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-2/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,720] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-04 11:53:21,720] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,726] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,728] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-2/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,728] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-04 11:53:21,728] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,735] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,737] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-2/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,737] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-04 11:53:21,737] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,742] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,744] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-2/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,744] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-04 11:53:21,744] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,751] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,753] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-2/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,753] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-04 11:53:21,754] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,760] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,762] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-2/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,762] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-04 11:53:21,763] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,771] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,773] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-2/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,774] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-04 11:53:21,774] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,779] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,781] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-2/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,782] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-04 11:53:21,783] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,790] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,792] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-2/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,792] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-04 11:53:21,792] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,800] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,801] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-2/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,802] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-04 11:53:21,802] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,808] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,810] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-2/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,812] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-04 11:53:21,812] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,818] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,820] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-2/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,820] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-04 11:53:21,820] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,827] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,828] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-2/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,829] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-04 11:53:21,829] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,836] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,838] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-2/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,838] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-04 11:53:21,838] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,843] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:53:21,845] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-2/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:53:21,845] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-04 11:53:21,845] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:53:21,885] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, input-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:53:21,930] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 3 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,932] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,937] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,937] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,937] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,938] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,938] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,938] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,938] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,938] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 33 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,938] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,938] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,938] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,938] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,938] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,938] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,939] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,939] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 45 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,939] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,940] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,940] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,940] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,941] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,941] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,941] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,941] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,941] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,941] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 39 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,941] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,941] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 9 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,942] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,942] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 27 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,942] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,942] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,942] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,942] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,942] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,942] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 21 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,942] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,943] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,943] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,943] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,943] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,943] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,943] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,943] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,943] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,943] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:21,943] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,953] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 12 milliseconds for epoch 20, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,954] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 17 milliseconds for epoch 20, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,955] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 17 milliseconds for epoch 20, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,955] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 17 milliseconds for epoch 20, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,956] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 18 milliseconds for epoch 20, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,956] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 18 milliseconds for epoch 20, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,956] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 18 milliseconds for epoch 20, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,957] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 19 milliseconds for epoch 20, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,958] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 19 milliseconds for epoch 20, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,959] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 20 milliseconds for epoch 20, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,959] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 19 milliseconds for epoch 20, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,960] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 19 milliseconds for epoch 20, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,960] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 19 milliseconds for epoch 20, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,960] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 19 milliseconds for epoch 20, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,961] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 20 milliseconds for epoch 20, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,961] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 19 milliseconds for epoch 20, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,961] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 19 milliseconds for epoch 20, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,962] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 20 milliseconds for epoch 20, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,962] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 20 milliseconds for epoch 20, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,963] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 21 milliseconds for epoch 20, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,963] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 20 milliseconds for epoch 20, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,963] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 20 milliseconds for epoch 20, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,965] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 21 milliseconds for epoch 20, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,965] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 22 milliseconds for epoch 20, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:21,966] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 23 milliseconds for epoch 20, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:53:50,496] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-b19e89d1-8e04-439e-af75-e04900e73284 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:50,521] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member rdkafka-b19e89d1-8e04-439e-af75-e04900e73284 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:50,542] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 1 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:53:50,576] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-b19e89d1-8e04-439e-af75-e04900e73284 for group gruppo for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:54:50,442] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: Removing member rdkafka-b19e89d1-8e04-439e-af75-e04900e73284 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:54:50,444] INFO [GroupCoordinator 2]: Group gruppo with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:54:50,448] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-b19e89d1-8e04-439e-af75-e04900e73284, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.1.114, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:55:09,272] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-44478466-d3ed-4e36-8070-c4fa388aa28f and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:55:09,276] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 2 (__consumer_offsets-37) (reason: Adding new member rdkafka-44478466-d3ed-4e36-8070-c4fa388aa28f with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:55:09,277] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 3 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:55:09,283] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-44478466-d3ed-4e36-8070-c4fa388aa28f for group gruppo for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:55:40,804] ERROR Error while writing to checkpoint file /tmp/kafka-logs-1/replication-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.io.FileNotFoundException: /tmp/kafka-logs-1/replication-offset-checkpoint.tmp (No such file or directory)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:291)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:234)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:184)
	at org.apache.kafka.server.common.CheckpointFile.write(CheckpointFile.java:78)
	at kafka.server.checkpoints.CheckpointFileWithFailureHandler.write(CheckpointFileWithFailureHandler.scala:37)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:68)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7(ReplicaManager.scala:1875)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7$adapted(ReplicaManager.scala:1875)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6(ReplicaManager.scala:1875)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6$adapted(ReplicaManager.scala:1874)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:563)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:561)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:919)
	at scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:889)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1874)
	at kafka.server.ReplicaManager.$anonfun$startHighWatermarkCheckPointThread$1(ReplicaManager.scala:271)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:116)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:831)
[2022-05-04 11:55:40,807] WARN [ReplicaManager broker=1] Stopping serving replicas in dir /tmp/kafka-logs-1 (kafka.server.ReplicaManager)
[2022-05-04 11:55:40,808] ERROR [ReplicaManager broker=1] Error while writing to highwatermark file in directory /tmp/kafka-logs-1 (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file /tmp/kafka-logs-1/replication-offset-checkpoint
Caused by: java.io.FileNotFoundException: /tmp/kafka-logs-1/replication-offset-checkpoint.tmp (No such file or directory)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:291)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:234)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:184)
	at org.apache.kafka.server.common.CheckpointFile.write(CheckpointFile.java:78)
	at kafka.server.checkpoints.CheckpointFileWithFailureHandler.write(CheckpointFileWithFailureHandler.scala:37)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:68)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7(ReplicaManager.scala:1875)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7$adapted(ReplicaManager.scala:1875)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6(ReplicaManager.scala:1875)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6$adapted(ReplicaManager.scala:1874)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:563)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:561)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:919)
	at scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:889)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1874)
	at kafka.server.ReplicaManager.$anonfun$startHighWatermarkCheckPointThread$1(ReplicaManager.scala:271)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:116)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:831)
[2022-05-04 11:55:40,817] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, provatop-0, __consumer_offsets-46, output-0, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-48, __consumer_offsets-12, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-8, __consumer_offsets-4, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:55:40,821] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, provatop-0, __consumer_offsets-46, output-0, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-48, __consumer_offsets-12, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-8, __consumer_offsets-4, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:55:40,858] WARN [ReplicaManager broker=1] Broker 1 stopped fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,provatop-0,__consumer_offsets-46,output-0,__consumer_offsets-36,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-48,__consumer_offsets-12,__consumer_offsets-26,__consumer_offsets-34,__consumer_offsets-8,__consumer_offsets-4,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-42,__consumer_offsets-18,__consumer_offsets-2,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory /tmp/kafka-logs-1. (kafka.server.ReplicaManager)
[2022-05-04 11:55:40,858] WARN Stopping serving logs in dir /tmp/kafka-logs-1 (kafka.log.LogManager)
[2022-05-04 11:55:40,862] ERROR Shutdown broker because all log dirs in /tmp/kafka-logs-1 have failed (kafka.log.LogManager)
[2022-05-04 11:55:41,208] WARN Unexpected exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client, it probably closed the socket: address = /127.0.0.1:42612, session = 0x10000fdd29b0000
	at org.apache.zookeeper.server.NIOServerCnxn.handleFailedRead(NIOServerCnxn.java:163)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:326)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:831)
[2022-05-04 11:55:41,857] ERROR Error while writing to checkpoint file /tmp/kafka-logs-2/replication-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.io.FileNotFoundException: /tmp/kafka-logs-2/replication-offset-checkpoint.tmp (No such file or directory)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:291)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:234)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:184)
	at org.apache.kafka.server.common.CheckpointFile.write(CheckpointFile.java:78)
	at kafka.server.checkpoints.CheckpointFileWithFailureHandler.write(CheckpointFileWithFailureHandler.scala:37)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:68)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7(ReplicaManager.scala:1875)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7$adapted(ReplicaManager.scala:1875)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6(ReplicaManager.scala:1875)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6$adapted(ReplicaManager.scala:1874)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:563)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:561)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:919)
	at scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:889)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1874)
	at kafka.server.ReplicaManager.$anonfun$startHighWatermarkCheckPointThread$1(ReplicaManager.scala:271)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:116)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:831)
[2022-05-04 11:55:41,860] WARN [ReplicaManager broker=2] Stopping serving replicas in dir /tmp/kafka-logs-2 (kafka.server.ReplicaManager)
[2022-05-04 11:55:41,861] ERROR [ReplicaManager broker=2] Error while writing to highwatermark file in directory /tmp/kafka-logs-2 (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file /tmp/kafka-logs-2/replication-offset-checkpoint
Caused by: java.io.FileNotFoundException: /tmp/kafka-logs-2/replication-offset-checkpoint.tmp (No such file or directory)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:291)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:234)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:184)
	at org.apache.kafka.server.common.CheckpointFile.write(CheckpointFile.java:78)
	at kafka.server.checkpoints.CheckpointFileWithFailureHandler.write(CheckpointFileWithFailureHandler.scala:37)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:68)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7(ReplicaManager.scala:1875)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$7$adapted(ReplicaManager.scala:1875)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6(ReplicaManager.scala:1875)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6$adapted(ReplicaManager.scala:1874)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:563)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:561)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:919)
	at scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:889)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1874)
	at kafka.server.ReplicaManager.$anonfun$startHighWatermarkCheckPointThread$1(ReplicaManager.scala:271)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:116)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:831)
[2022-05-04 11:55:41,863] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, input-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:55:41,864] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, input-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:55:41,897] WARN [ReplicaManager broker=2] Broker 2 stopped fetcher for partitions __consumer_offsets-21,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-47,__consumer_offsets-3,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-17,__consumer_offsets-13,__consumer_offsets-43,__consumer_offsets-39,__consumer_offsets-29,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-31,input-0,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5 and stopped moving logs for partitions  because they are in the failed log directory /tmp/kafka-logs-2. (kafka.server.ReplicaManager)
[2022-05-04 11:55:41,898] WARN Stopping serving logs in dir /tmp/kafka-logs-2 (kafka.log.LogManager)
[2022-05-04 11:55:41,904] ERROR Shutdown broker because all log dirs in /tmp/kafka-logs-2 have failed (kafka.log.LogManager)
[2022-05-04 11:55:42,368] WARN Unexpected exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client, it probably closed the socket: address = /[0:0:0:0:0:0:0:1]:40480, session = 0x10000fdd29b0001
	at org.apache.zookeeper.server.NIOServerCnxn.handleFailedRead(NIOServerCnxn.java:163)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:326)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:831)
[2022-05-04 11:55:55,133] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:55:55,136] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:55:55,142] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:55:55,143] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:55:55,143] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:55:55,143] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:55:55,145] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:55:55,145] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:55:55,146] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 11:55:55,146] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-04 11:55:55,153] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-04 11:55:55,179] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:55:55,179] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:55:55,180] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:55:55,180] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:55:55,181] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:55:55,181] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 11:55:55,181] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-04 11:55:55,202] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@ca263c2 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-04 11:55:55,209] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:55:55,225] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,225] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,226] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,226] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,226] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,226] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,226] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,226] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,226] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,226] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,228] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,228] INFO Server environment:host.name=fedora (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,228] INFO Server environment:java.version=16.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,228] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,228] INFO Server environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,229] INFO Server environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,229] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,229] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,229] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,229] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,229] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,229] INFO Server environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,229] INFO Server environment:user.name=della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,229] INFO Server environment:user.home=/home/della (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,229] INFO Server environment:user.dir=/home/della/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,229] INFO Server environment:os.memory.free=495MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,229] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,230] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,230] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,230] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,231] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,231] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,231] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,231] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,231] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,233] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-04 11:55:55,236] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,237] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,240] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:55:55,240] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 11:55:55,241] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:55:55,242] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:55:55,242] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:55:55,242] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:55:55,242] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:55:55,242] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 11:55:55,245] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,245] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,245] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,261] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:55:55,262] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 11:55:55,266] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:55:55,272] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 11:55:55,293] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:55:55,293] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 11:55:55,293] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:55:55,294] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:55:55,302] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-04 11:55:55,305] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.537 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-05-04 11:55:55,324] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x537, and digest value as 304119538351 (org.apache.zookeeper.server.DataTree)
[2022-05-04 11:55:55,378] INFO 113 txns loaded in 34 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:55:55,378] INFO Snapshot loaded in 84 ms, highest zxid is 0x5a8, digest is 322699438458 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 11:55:55,378] INFO Snapshotting: 0x5a8 to /tmp/zookeeper/version-2/snapshot.5a8 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 11:55:55,383] INFO Snapshot taken in 6 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:55:55,405] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-04 11:55:55,406] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-04 11:55:55,445] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-04 11:55:55,447] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-04 11:56:13,283] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:56:13,675] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:56:13,860] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:56:13,874] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:56:13,876] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:56:13,908] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:56:13,918] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,919] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,919] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,919] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,919] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,919] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,920] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,920] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,920] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,920] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,920] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,920] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,920] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,920] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,921] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,921] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,921] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,921] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,926] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:13,938] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:56:13,950] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:56:13,954] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:56:13,958] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:56:13,959] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:56:13,964] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:40482, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:56:13,978] INFO Creating new log file: log.5a9 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-04 11:56:13,993] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100010076580000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:56:14,003] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:56:14,171] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:56:14,449] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:56:14,464] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:56:14,473] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:56:14,567] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:56:14,600] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:56:14,703] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:56:14,706] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:56:14,708] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:56:14,723] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:56:14,750] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:56:14,825] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 11:56:14,838] INFO Attempting recovery for all logs in /tmp/kafka-logs-2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:56:14,854] INFO Loaded 0 logs in 28ms. (kafka.log.LogManager)
[2022-05-04 11:56:14,855] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:56:14,861] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:56:14,875] INFO Expiring session 0x10000fdd29b0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:56:14,875] INFO Expiring session 0x10000fdd29b0001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 11:56:14,937] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 11:56:15,481] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:56:15,499] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 11:56:15,781] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 11:56:15,789] INFO starting (kafka.server.KafkaServer)
[2022-05-04 11:56:15,791] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 11:56:15,825] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:56:15,840] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,841] INFO Client environment:host.name=fedora (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,842] INFO Client environment:java.version=16.0.2 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,842] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,842] INFO Client environment:java.home=/usr/local/java/jdk-16 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,842] INFO Client environment:java.class.path=/home/della/kafka/bin/../libs/activation-1.1.1.jar:/home/della/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/della/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/della/kafka/bin/../libs/audience-annotations-0.5.0.jar:/home/della/kafka/bin/../libs/commons-cli-1.4.jar:/home/della/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/della/kafka/bin/../libs/connect-api-3.1.0.jar:/home/della/kafka/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/della/kafka/bin/../libs/connect-file-3.1.0.jar:/home/della/kafka/bin/../libs/connect-json-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-3.1.0.jar:/home/della/kafka/bin/../libs/connect-mirror-client-3.1.0.jar:/home/della/kafka/bin/../libs/connect-runtime-3.1.0.jar:/home/della/kafka/bin/../libs/connect-transforms-3.1.0.jar:/home/della/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/della/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/della/kafka/bin/../libs/jackson-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-core-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-databind-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/della/kafka/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/della/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/della/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/della/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/della/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/della/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/della/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/della/kafka/bin/../libs/javassist-3.27.0-GA.jar:/home/della/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/della/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/della/kafka/bin/../libs/jaxb-api-2.3.0.jar:/home/della/kafka/bin/../libs/jersey-client-2.34.jar:/home/della/kafka/bin/../libs/jersey-common-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/home/della/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/della/kafka/bin/../libs/jersey-hk2-2.34.jar:/home/della/kafka/bin/../libs/jersey-server-2.34.jar:/home/della/kafka/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/della/kafka/bin/../libs/jline-3.12.1.jar:/home/della/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/della/kafka/bin/../libs/jose4j-0.7.8.jar:/home/della/kafka/bin/../libs/kafka_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-clients-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-metadata-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-raft-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-server-common-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-shell-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-storage-api-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/della/kafka/bin/../libs/kafka-tools-3.1.0.jar:/home/della/kafka/bin/../libs/log4j-1.2.17.jar:/home/della/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/della/kafka/bin/../libs/maven-artifact-3.8.1.jar:/home/della/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/della/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/della/kafka/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-codec-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-handler-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/della/kafka/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/della/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/della/kafka/bin/../libs/paranamer-2.8.jar:/home/della/kafka/bin/../libs/plexus-utils-3.2.1.jar:/home/della/kafka/bin/../libs/reflections-0.9.12.jar:/home/della/kafka/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/della/kafka/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/della/kafka/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/della/kafka/bin/../libs/scala-library-2.13.6.jar:/home/della/kafka/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/della/kafka/bin/../libs/scala-reflect-2.13.6.jar:/home/della/kafka/bin/../libs/slf4j-api-1.7.30.jar:/home/della/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/della/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/home/della/kafka/bin/../libs/trogdor-3.1.0.jar:/home/della/kafka/bin/../libs/zookeeper-3.6.3.jar:/home/della/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/home/della/kafka/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,844] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,844] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,845] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,845] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,845] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,845] INFO Client environment:os.version=5.17.4-100.fc34.x86_64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,846] INFO Client environment:user.name=della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,848] INFO Client environment:user.home=/home/della (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,849] INFO Client environment:user.dir=/home/della/kafka (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,850] INFO Client environment:os.memory.free=987MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,853] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,853] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,861] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@609bcfb6 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 11:56:15,882] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 11:56:15,895] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:56:15,907] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:56:15,915] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:56:15,915] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:56:15,926] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:40484, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:56:15,939] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100010076580001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 11:56:15,948] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 11:56:16,134] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:56:16,143] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-04 11:56:16,167] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 11:56:16,205] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:56:16,236] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:56:16,262] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:16,265] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:16,268] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:16,271] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:16,301] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:56:16,382] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:56:16,411] INFO Stat of the created znode at /brokers/ids/2 is: 1481,1481,1651658176403,1651658176403,1,0,0,72058695535034368,196,0,1481
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:56:16,413] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://fedora:9093, czxid (broker epoch): 1481 (kafka.zk.KafkaZkClient)
[2022-05-04 11:56:16,464] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 11:56:16,473] INFO Cluster ID = c4EBznEsSp-FYD9RI_EBfA (kafka.server.KafkaServer)
[2022-05-04 11:56:16,477] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-04 11:56:16,526] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:16,532] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:16,547] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:16,583] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:56:16,608] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 11:56:16,602] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:16,672] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:16,742] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:56:16,744] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:56:16,750] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:56:16,755] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:56:16,757] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:56:16,758] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:56:16,767] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 11:56:16,829] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2022-05-04 11:56:16,869] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:16,922] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 11:56:16,938] INFO Attempting recovery for all logs in /tmp/kafka-logs-1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 11:56:16,961] INFO Loaded 0 logs in 39ms. (kafka.log.LogManager)
[2022-05-04 11:56:16,963] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 11:56:16,973] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 11:56:16,983] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:56:17,087] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:56:17,131] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:56:17,131] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:56:17,140] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:56:17,140] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:56:17,140] INFO Kafka startTimeMs: 1651658177132 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:56:17,142] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-04 11:56:17,237] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker fedora:9093 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:56:17,264] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9093 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:56:17,639] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, input-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:56:17,679] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:56:17,812] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:17,853] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-2/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:17,858] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-04 11:56:17,860] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:17,899] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:17,906] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-2/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:17,907] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-04 11:56:17,907] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:17,923] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:17,927] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-2/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:17,927] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-04 11:56:17,927] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:17,947] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:17,954] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-2/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:17,955] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-04 11:56:17,955] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:17,967] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:17,971] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-2/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:17,971] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-04 11:56:17,972] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:17,982] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:17,987] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-2/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:17,987] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-04 11:56:17,987] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,001] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,004] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-2/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,005] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-04 11:56:18,005] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,022] INFO [LogLoader partition=input-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,024] INFO Created log for partition input-0 in /tmp/kafka-logs-2/input-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:56:18,024] INFO [Partition input-0 broker=2] No checkpointed highwatermark is found for partition input-0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,025] INFO [Partition input-0 broker=2] Log loaded for partition input-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,036] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,041] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-2/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,041] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-04 11:56:18,041] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,056] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,058] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-2/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,059] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-04 11:56:18,059] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,070] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,074] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-2/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,075] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-04 11:56:18,075] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,088] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,091] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-2/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,091] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-04 11:56:18,091] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,102] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,105] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-2/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,106] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-04 11:56:18,106] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,116] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,119] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-2/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,120] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-04 11:56:18,129] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,140] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,143] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-2/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,143] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-04 11:56:18,144] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,155] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,157] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-2/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,157] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-04 11:56:18,157] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,171] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,179] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-2/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,179] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-04 11:56:18,179] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,189] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,194] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-2/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,194] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-04 11:56:18,194] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,206] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,208] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-2/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,208] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-04 11:56:18,209] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,222] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,224] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-2/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,224] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-04 11:56:18,225] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,231] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,235] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-2/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,235] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-04 11:56:18,236] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,242] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,244] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-2/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,244] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-04 11:56:18,244] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,254] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,256] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-2/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,256] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-04 11:56:18,256] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,265] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,268] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-2/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,269] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-04 11:56:18,269] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,278] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,281] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-2/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,281] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-04 11:56:18,281] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,293] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:18,295] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-2/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:18,295] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-04 11:56:18,296] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:18,318] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 3 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,319] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,323] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,323] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,323] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,323] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,324] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,324] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,324] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,324] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,324] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 33 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,324] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,325] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,325] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,325] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,325] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,325] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,325] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,325] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 45 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,325] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,325] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,325] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,326] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,326] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,326] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,326] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,326] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,326] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,326] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 39 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,326] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,326] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 9 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,326] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,326] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 27 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,326] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,327] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,327] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,327] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,327] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,327] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 21 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,327] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,327] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,327] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,327] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,327] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,327] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,327] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,328] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,328] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,328] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,328] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,362] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 29 milliseconds for epoch 20, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,378] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 55 milliseconds for epoch 20, of which 40 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,379] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 55 milliseconds for epoch 20, of which 55 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,381] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 56 milliseconds for epoch 20, of which 55 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,381] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 57 milliseconds for epoch 20, of which 57 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,381] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 56 milliseconds for epoch 20, of which 56 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,382] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 57 milliseconds for epoch 20, of which 57 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,382] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 57 milliseconds for epoch 20, of which 57 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,383] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 58 milliseconds for epoch 20, of which 57 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,383] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 58 milliseconds for epoch 20, of which 58 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,396] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 71 milliseconds for epoch 20, of which 70 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,397] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 71 milliseconds for epoch 20, of which 71 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,398] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 72 milliseconds for epoch 20, of which 71 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,398] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 72 milliseconds for epoch 20, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,399] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 72 milliseconds for epoch 20, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,399] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 73 milliseconds for epoch 20, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,399] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 72 milliseconds for epoch 20, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,400] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 73 milliseconds for epoch 20, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,400] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 73 milliseconds for epoch 20, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,401] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 74 milliseconds for epoch 20, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,401] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 74 milliseconds for epoch 20, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,401] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 74 milliseconds for epoch 20, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,402] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 75 milliseconds for epoch 20, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,402] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 74 milliseconds for epoch 20, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,402] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 74 milliseconds for epoch 20, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:18,445] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 11:56:18,451] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-04 11:56:18,501] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:56:18,518] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:56:18,540] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:18,542] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:18,543] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:18,545] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:18,568] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 11:56:18,634] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 11:56:18,656] INFO Stat of the created znode at /brokers/ids/1 is: 1511,1511,1651658178646,1651658178646,1,0,0,72058695535034369,196,0,1511
 (kafka.zk.KafkaZkClient)
[2022-05-04 11:56:18,658] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://fedora:9092, czxid (broker epoch): 1511 (kafka.zk.KafkaZkClient)
[2022-05-04 11:56:18,828] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:18,856] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:18,868] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:18,893] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,918] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:18,947] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:56:18,953] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 11:56:18,956] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 11:56:18,995] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 11:56:19,020] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 11:56:19,054] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:56:19,071] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 11:56:19,072] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 11:56:19,078] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:56:19,078] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:56:19,078] INFO Kafka startTimeMs: 1651658179072 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 11:56:19,082] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-04 11:56:19,220] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker fedora:9093 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:56:19,223] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker fedora:9093 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 11:56:19,317] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,346] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-1/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,351] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-04 11:56:19,352] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,365] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,373] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-1/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,373] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-04 11:56:19,373] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,380] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,385] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-1/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,385] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-04 11:56:19,386] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,393] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,396] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-1/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,396] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-04 11:56:19,397] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,407] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,409] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-1/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,409] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-04 11:56:19,409] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,416] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,418] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-1/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,418] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-04 11:56:19,419] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,425] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,427] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-1/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,428] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-04 11:56:19,428] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,439] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,440] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-1/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,441] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-04 11:56:19,441] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,448] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,449] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-1/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,449] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-04 11:56:19,450] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,455] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,457] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-1/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,457] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-04 11:56:19,457] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,462] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,465] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-1/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,465] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-04 11:56:19,465] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,473] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,475] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-1/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,475] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-04 11:56:19,475] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,481] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,483] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-1/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,483] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,483] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,490] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,491] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-1/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,491] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-04 11:56:19,491] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,497] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,499] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-1/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,499] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-04 11:56:19,500] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,506] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,508] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-1/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,508] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-04 11:56:19,508] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,515] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,516] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-1/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,517] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-04 11:56:19,517] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,522] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,523] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-1/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,524] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-04 11:56:19,524] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,532] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,534] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-1/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,535] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-04 11:56:19,535] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,541] INFO [LogLoader partition=output-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,543] INFO Created log for partition output-0 in /tmp/kafka-logs-1/output-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:56:19,543] INFO [Partition output-0 broker=1] No checkpointed highwatermark is found for partition output-0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,544] INFO [Partition output-0 broker=1] Log loaded for partition output-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,552] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,554] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-1/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,554] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-04 11:56:19,554] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,561] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,563] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-1/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,563] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-04 11:56:19,563] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,572] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,574] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-1/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,574] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-04 11:56:19,574] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,580] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,581] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-1/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,582] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-04 11:56:19,582] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,589] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,591] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-1/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,592] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-04 11:56:19,592] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,598] INFO [LogLoader partition=provatop-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,600] INFO Created log for partition provatop-0 in /tmp/kafka-logs-1/provatop-0 with properties {} (kafka.log.LogManager)
[2022-05-04 11:56:19,601] INFO [Partition provatop-0 broker=1] No checkpointed highwatermark is found for partition provatop-0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,601] INFO [Partition provatop-0 broker=1] Log loaded for partition provatop-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,607] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 11:56:19,610] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-1/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-04 11:56:19,610] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-04 11:56:19,610] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 11:56:19,651] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, provatop-0, __consumer_offsets-46, output-0, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-48, __consumer_offsets-12, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-8, __consumer_offsets-4, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:56:19,694] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,695] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,700] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,701] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,702] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,702] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,702] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,702] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,702] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,702] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,702] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,702] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,702] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,702] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,703] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,703] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,703] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,703] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,703] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,703] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,703] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,703] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,703] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,703] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,703] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,703] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,703] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,704] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,704] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,704] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,704] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,704] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,704] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,704] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,704] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,704] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,704] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,704] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,704] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,705] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,705] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,705] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,705] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,705] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,705] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,705] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,705] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,705] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,705] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:56:19,705] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,716] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 16 milliseconds for epoch 15, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,717] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 16 milliseconds for epoch 15, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,718] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 16 milliseconds for epoch 15, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,718] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 16 milliseconds for epoch 15, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,719] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 17 milliseconds for epoch 15, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,719] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 17 milliseconds for epoch 15, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,720] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 17 milliseconds for epoch 15, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,720] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 17 milliseconds for epoch 15, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,721] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 18 milliseconds for epoch 15, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,721] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 18 milliseconds for epoch 15, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,721] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 18 milliseconds for epoch 15, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,722] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 19 milliseconds for epoch 15, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,722] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 19 milliseconds for epoch 15, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,722] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 18 milliseconds for epoch 15, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,723] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 19 milliseconds for epoch 15, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,723] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 19 milliseconds for epoch 15, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,724] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 20 milliseconds for epoch 15, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,724] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 20 milliseconds for epoch 15, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,724] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 20 milliseconds for epoch 15, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,725] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 20 milliseconds for epoch 15, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,725] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 20 milliseconds for epoch 15, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,725] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 20 milliseconds for epoch 15, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,726] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 21 milliseconds for epoch 15, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,726] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 21 milliseconds for epoch 15, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:56:19,726] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 21 milliseconds for epoch 15, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 11:57:41,355] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group gruppo in Empty state. Created a new member id rdkafka-e7e7c290-dace-440b-a1f8-c886adbb5f9f and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:57:41,371] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member rdkafka-e7e7c290-dace-440b-a1f8-c886adbb5f9f with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:57:41,388] INFO [GroupCoordinator 2]: Stabilized group gruppo generation 1 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:57:41,426] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-e7e7c290-dace-440b-a1f8-c886adbb5f9f for group gruppo for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:58:07,960] INFO [LocalLog partition=input-0, dir=/tmp/kafka-logs-2] Rolled new log segment at offset 14726362 in 5 ms. (kafka.log.LocalLog)
[2022-05-04 11:58:07,974] INFO [ProducerStateManager partition=input-0] Wrote producer snapshot at offset 14726362 with 0 producer ids in 12 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:58:31,582] INFO [LocalLog partition=input-0, dir=/tmp/kafka-logs-2] Rolled new log segment at offset 29452345 in 35 ms. (kafka.log.LocalLog)
[2022-05-04 11:58:31,582] INFO [ProducerStateManager partition=input-0] Wrote producer snapshot at offset 29452345 with 0 producer ids in 0 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:58:41,369] INFO [GroupCoordinator 2]: Preparing to rebalance group gruppo in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: Removing member rdkafka-e7e7c290-dace-440b-a1f8-c886adbb5f9f on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:58:41,376] INFO [GroupCoordinator 2]: Group gruppo with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:58:41,381] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-e7e7c290-dace-440b-a1f8-c886adbb5f9f, groupInstanceId=None, clientId=rdkafka, clientHost=/192.168.1.114, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(roundrobin)) has left group gruppo through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 11:58:51,480] INFO [LocalLog partition=input-0, dir=/tmp/kafka-logs-2] Rolled new log segment at offset 44180461 in 12 ms. (kafka.log.LocalLog)
[2022-05-04 11:58:51,480] INFO [ProducerStateManager partition=input-0] Wrote producer snapshot at offset 44180461 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2022-05-04 11:59:03,445] ERROR Error while appending records to input-0 in dir /tmp/kafka-logs-2 (kafka.server.LogDirFailureChannel)
java.io.IOException: No space left on device
	at java.base/sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at java.base/sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:62)
	at java.base/sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:113)
	at java.base/sun.nio.ch.IOUtil.write(IOUtil.java:79)
	at java.base/sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:285)
	at org.apache.kafka.common.record.MemoryRecords.writeFullyTo(MemoryRecords.java:92)
	at org.apache.kafka.common.record.FileRecords.append(FileRecords.java:188)
	at kafka.log.LogSegment.append(LogSegment.scala:158)
	at kafka.log.LocalLog.append(LocalLog.scala:394)
	at kafka.log.UnifiedLog.append(UnifiedLog.scala:907)
	at kafka.log.UnifiedLog.appendAsLeader(UnifiedLog.scala:718)
	at kafka.cluster.Partition.$anonfun$appendRecordsToLeader$1(Partition.scala:1057)
	at kafka.cluster.Partition.appendRecordsToLeader(Partition.scala:1045)
	at kafka.server.ReplicaManager.$anonfun$appendToLocalLog$6(ReplicaManager.scala:924)
	at scala.collection.StrictOptimizedMapOps.map(StrictOptimizedMapOps.scala:28)
	at scala.collection.StrictOptimizedMapOps.map$(StrictOptimizedMapOps.scala:27)
	at scala.collection.mutable.HashMap.map(HashMap.scala:35)
	at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:912)
	at kafka.server.ReplicaManager.appendRecords(ReplicaManager.scala:583)
	at kafka.server.KafkaApis.handleProduceRequest(KafkaApis.scala:658)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:169)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:75)
	at java.base/java.lang.Thread.run(Thread.java:831)
[2022-05-04 11:59:03,490] WARN [ReplicaManager broker=2] Stopping serving replicas in dir /tmp/kafka-logs-2 (kafka.server.ReplicaManager)
[2022-05-04 11:59:03,495] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, input-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5) (kafka.server.ReplicaFetcherManager)
[2022-05-04 11:59:03,496] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-29, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-31, input-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 11:59:03,553] WARN [ReplicaManager broker=2] Broker 2 stopped fetcher for partitions __consumer_offsets-21,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-47,__consumer_offsets-3,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-17,__consumer_offsets-13,__consumer_offsets-43,__consumer_offsets-39,__consumer_offsets-29,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-31,input-0,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5 and stopped moving logs for partitions  because they are in the failed log directory /tmp/kafka-logs-2. (kafka.server.ReplicaManager)
[2022-05-04 11:59:03,554] WARN Stopping serving logs in dir /tmp/kafka-logs-2 (kafka.log.LogManager)
[2022-05-04 11:59:03,567] ERROR Shutdown broker because all log dirs in /tmp/kafka-logs-2 have failed (kafka.log.LogManager)
[2022-05-04 11:59:04,061] WARN Unexpected exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client, it probably closed the socket: address = /[0:0:0:0:0:0:0:1]:40482, session = 0x100010076580000
	at org.apache.zookeeper.server.NIOServerCnxn.handleFailedRead(NIOServerCnxn.java:163)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:326)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:831)
[2022-05-04 11:59:20,875] INFO Expiring session 0x100010076580000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
